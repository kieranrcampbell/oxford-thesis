%************************************************
\chapter{Modelling bifurcations with a Bayesian mixture of factor analysers}\label{ch:mfachap} % $\mathbb{ZNR}$
%************************************************


\section{Introduction}

%
% Trajectory analysis of single-cell RNA-seq (scRNA-seq) data has become a popular method that attempts to re-infer lost temporal information such as a cell's differentiation state \cite{wagner2016revealing,bacher2016design}. Such analyses reconstruct a measure of a cell's progression through some biological process, known as a \emph{pseudotime}. Recently, attention has turned to modelling bifurcations where part-way along such trajectories cells undergo some fate decision and branch into two or more distinct cell types.

So far we have focussed on the \emph{single-trajectory} case, where cells have a single fate and progress uniformly towards it. Chapter 2 considered probabilistic inference of trajectories in reduced-dimension space, while chapter 3 extended such ideas to generatively model the expression of a small set of marker genes.

However, often cells undergo some fate decision and their expression programmes bifurcate into two or more end points. Examples include progenitor cells that differentiate into distinct cell types or stressed cells that may either recover or trigger apoptosis.

Several methods have been proposed to infer bifurcation structure from single-cell data. Wishbone \cite{setty2016wishbone} constructs a $k$-nearest neighbour graph and uses shortest paths from a \emph{root} cell to define pseudotimes, using inconsistencies over multiple paths to detect bifurcations.  Diffusion Pseudotime (DPT) \cite{haghverdi2016diffusion} similarly constructs a transition matrix where each entry may be interpreted as a diffusion distance between two cells. Bifurcations are inferred by identifying the anticorrelation structure of random walks from both a root cell and its maximally distant cell. While DPT arguably has a probabilistic interpretation, neither method specifies a fully generative model that incorporates measurement noise, while both infer bifurcations after constructing pseudotimes. A further algorithm Monocle  \cite{Qiu2017-eu} learns pseudotimes based on dimensionality reduction using the DDRTree algorithm \cite{mao2015novel} and provides post-hoc inference of genes involved in the bifurcation process using generalised linear models.

Consequently, we we propose a Bayesian hierarchical mixture of factor analysers for inferring bifurcations from single-cell data.
%Factor analysis and its close relative principal component analysis (PCA) are frequently used in the context of single-cell gene expression modelling, both for visualisation and trajectory inference (see e.g. \cite{pierson2015zifa,campbell2016ouija}).
Since developmental bifurcations involve two related processes it is therefore natural to extend such models to involve a mixture of two factor analysers in a Bayesian hierarchical setting that relates expression patterns between branches.

The model we propose is unique compared to existing bifurcation inference methods methods in the following: (1) by specifying a fully generative probabilistic model we incorporate measurement noise into inference and provide full uncertainty estimates for all parameters, (2) we simultaneously infer cell ``pseudotimes'' and branching structure as opposed to post-hoc branching inference as is typically performed, and (3) our hierarchical shrinkage prior structure automatically detects which features are involved in the bifurcation, providing statistical support for detecting which genes drive fate decisions.

In this chapter, we introduce our model and apply it to both a synthetic datasets and demonstrate its consistency with existing algorithms on real single-cell data. We further propose a zero-inflated Empirical-Bayes-like variant that takes into account zero-inflation and quantify the levels of dropout at which such models are beneficial.  We highlight the multiple natural solutions to bifurcation inference when using gene expression data alone and finally discuss both the merits and drawbacks of using such a unified probabilistic model.


\section{Methods}

\subsection{Statistical model}

We begin with an $N \times G$ matrix of suitably normalised\footnote{Such as $\log(\text{TPM} + 1)$ or $\log(\text{FPKM} + 1)$.} gene expression measurements for $N$ cells and $G$ genes, where $\by_n$ denotes the $n^{th}$ row vector corresponding to the expression measurement of cell $n$. We assign a pseudotime $t_n$ to each cell along with a binary variable $\gamma_n$ indicating to which of $B$ branches cell $n$ belongs:

\begin{equation}
\gamma_n = b \; \mbox{if cell $n$ on branch $b$}
\end{equation}

with $b \in 1,\ldots,B$.

The pseudotime $t_n$ is a surrogate measure of a cell's progression along a trajectory while it is the behaviour of the genes - given by the factor loading matrix - that changes between the branches. We therefore introduce $B$ factor loading matrices $\Lambda_b = [ \bc_b \; \bk_b], \; b \in 1, \ldots, B$ for each branch modelled. Here, $\bc_b$ represents the gene-specific intercepts of expression while $\bk_b$ can be thought of as the gene-specific gradient along pseudotime.

% We subsequently only reference the factor loading intercept $\bc$ and factor loading gradient $\bk$ due to their differing prior structures.

The likelihood of a given cell's gene expression measurement conditional on all the parameters is then given by % a normal with a mean formed of the product of the pseudotime with the factor loading gradient summed with the factor loading intercept specific to the cell's branch:

\begin{equation}
\by_n | \gamma_n, \Lambda_{\gamma_n}, t_n, \btau  \sim \norm(\cgi + \kgi t_n, \mbSigma)
\end{equation}

where $\mbSigma = \text{diag}(\tau_1, \ldots, \tau_G)$ and $\btau$ is a $G$-length vector of measurement precisions.

We seek a prior structure on the loading matrix that (a) encourages the behaviour of genes to be identical across branches while (b) identifying the subset of genes that deviate from this and are differentially regulated across the branches. It is therefore reasonable that the factor loading gradients $\bk_\gamma$ should be similar to each other unless the data suggests otherwise. We therefore place a prior of the form

\begin{equation}
[\kgi]_g \sim \norm(\theta_g,  \chi^{-1}_g)
\end{equation}

where $\mbtheta = (\theta_1, \ldots, \theta_g)$ denotes a common factor gradient across branches. This has similar elements to Automatic Relevance Determination (ARD) models % (also known as Sparse Bayesian Learning)
with the difference that rather than shrinking regression coefficients to zero to induce sparsity we shrink factor loading gradients towards a common value to induce similar behaviour between mixture components. We can then inspect the posterior precision %similar to ARD
to identify genes involved in the bifurcation: if $\chi_g$ is very large then the model is sure that $k_{0g} \approx k_{1g}$ and gene $g$ is not involved in the bifurcation; however, if $\chi_g$ is relatively small then $|k_{0g} - k_{1g}| \gg 0$ and the model indicates that $g$ is involved in the bifurcation\footnote{Note that we only place this prior structure on $k$ as the intercepts $c$ can be identical but the genes still exhibit differential regulation through different $k$s.}.

With these considerations the overall model becomes

\begin{equation} \label{eq:mfamodel}
\begin{aligned}
\bm \omega & \sim \text{Dirichlet}(1 / B, \ldots, 1 / B) \\
\gamma_n & \sim \text{Categorical}(\bm \omega) \\
\eta & \sim \norm(\tilde{\eta}, \tau_\eta^{-1}) \\
\theta_g & \sim \norm(\tilde{\theta}, \tau_\theta^{-1}) \\
\chi_g & \sim \mathrm{Gamma}(\alpha_\chi, \beta_\chi) \\
\cgi & \sim \norm(\eta, \tau_c^{-1}) \\
\kgi & \sim \norm(\bm \theta, \bm \chi^{-1} \mathbb{1}_G) \\
t_n & \sim \norm(0, 1) \\
\btau & \sim \mathrm{Gamma}(\alpha, \beta) \\
\by_n & \sim \norm(\cgi + \kgi t_n, \btau^{-1} \mathbb{1}_G)
\end{aligned}
\end{equation}

where $\tilde{\eta}$, $\tilde{\theta}$, $\tau_\eta$, $\tau_\theta$, $\tau_c$, $\alpha_\chi$, $\beta_\chi$, $\alpha$ and $\beta$ are hyperparameters fixed by the user. By default we set the noninformative prior $\alpha_\chi = \beta_\chi = 10^{-2}$ to maximise how informative the posterior of $\bm \chi$ is in identifying genes that show differential expression across the branches.

\subsection{Inference} \label{sec:gibbs}

As the model exhibits complete conditional conjugacy, inference was performed using Gibbs sampling. Briefly, Gibbs sampling is a Markov Chain Monte-Carlo (MCMC) algorithm for drawing a sequence of $T$ samples $\btheta^1, \ldots, \bm \theta^T$ that approximate some target distribution $p(\btheta | x)$ that is analytically intractable, i.e. for which we cannot write down an exact expression. Given the parameter vector $\btheta = (\theta_1, \ldots, \theta_P)$, Gibbs sampling requires analytical expressions (or at least the ability to quickly generate samples from) the conditional distributions $p(\theta_p | \btheta_{-p}, x)$ where $\btheta_{-p}$ is the set of parameters other than $p$. Gibbs sampling then proceeds by consecutively drawing

\begin{equation}
	%\begin{aligned}
		\theta_p^{t+1}  \sim p(\theta_p | \btheta^t_{-p}, x)
	%\end{aligned}
\end{equation}

consecutively for all variables $p = 1, \ldots, P$ up to some predefined number of iterations $T$. The resulting samples $\btheta^1, \ldots, \bm \theta^T$ asymptotically converge in the limit $T \rightarrow \infty$ to the target distribution $p(\btheta | x)$.

Analytical expression for the conditional Gibbs updates for our \texttt{mfa} model are given in appendix \ref{app:mfa_updates}. This is implemented in the \texttt{R} package \texttt{mfa} available at \url{http://www.github.com/kieranrcampbell/mfa}. \texttt{R} is particularly slow for calculating such Gibbs updates as frequent subsetting of assignment vectors occurs. Therefore, computation of the updates was implemented in \texttt{C++} and linked to the \texttt{R} package using \texttt{Rcpp}, leading to orders of magnitude speed up in the calculation of some quantities.

\subsection{Modelling zero-inflation}

Single-cell RNA-seq data is known to exhibit \emph{dropout}, where lowly expressed genes register as zero counts. Several computational methods attempt to correct for this by modelling the observed expression as a mixture of a point-mass at zero representing dropout and an \emph{amplified} component representing true expression. However, the probability of measuring a zero is not constant but is inversely proportional to the latent expression, as the smaller the input quantity of mRNA the higher the probability of a failure of reverse-transcription.

As a solution to this, several methods model a dropout probability dependent on the latent expression. For example, SCDE \cite{Kharchenko2014} is a statistical model for single-cell differential expression which models the dropout probability of a gene as a logistic regression on the latent expression as part of a mixture-of-experts model.
In a further example, ZIFA \cite{pierson2015zifa} proposes a double-exponential dropout model where $p(\text{dropout}) \propto \exp(-\lambda x^2)$ and $x$ is the latent expression and $\lambda$ is a constant dropout parameter.

Therefore, accounting for zero-inflation in our mixture-of-factor analysers model is equivalent to modifying the likelihood to a mixture of an amplified component and dropout component depending on the latent expression. However, the difficulty here is that we must sample from the conditional distribution $p(\lambda | \cdot)$ (where $\cdot$ is all parameters and data other than $\lambda$), which to the best of our knowledge does not exist analytically.

\begin{figure}%[h]
	\centering
	\includegraphics[width=\textwidth]{gfx/ch4/s1_dropout}
	\caption{Dropout relationships in single-cell RNA-seq data for two scRNA-seq datasets. An exponential dropout model (blue) empirically fits the data better than double exponential (red).} \label{fig:dropout}
\end{figure}

As a solution to this we propose an Empirical-Bayes like procedure to estimate $\lambda$ globally then infer the latent expression $x$ through further Gibbs updates. First we note that a single exponential dropout empirically fits the dropout relations in single-cell RNA-seq datasets better than the double exponential dropout (figure \ref{fig:dropout}).

We subsequently modify the likelihood to give a per-gene dropout probability of

\begin{equation}
p(\text{dropout in gene $g$}) = \exp(-\lambda \sum_{n=1}^N x_{ng})
\end{equation}

 which depends on the mean latent expression level of the gene. While this is of course an approximation and we expect the probability of a dropout to be specific to each gene in each cell depending on the latent expression, this allows us to estimate $\lambda$ by fitting the maximum likelihood exponential curve of the proportion of cells a gene is expressed in against the mean expression level (similar to figure \ref{fig:dropout}) using the \texttt{R} function \texttt{nls}. Thus the modified likelihood becomes

\begin{equation}
\begin{aligned}
\bx_n & \sim \norm(\cgi + \kgi t_n,\mbSigma) \\
h_{ng} & \sim \mathrm{Bernoulli}(\exp\left(-\frac{\lambda}{N} \sum_{n'} x_{n'g} \right)) \\
y_{ng} & = \begin{cases} x_{ng} &\mbox{if $h_{ng} = 0$}  \\
0 & \mbox{if $h_{ng} = 1$} \end{cases}
\end{aligned}
\end{equation}

Note that since $h_{ng}$ is effectively observed we only need to Gibbs sample $x_{ng}$ for which $h_{ng} = 1$. The conditional distribution for $x_{ng}$ is then given by

\begin{equation}
x_{ng} | \cdot \sim \norm\left( \mu_{ng} - \frac{\lambda}{N \tau_g}, \tau_g^{-1} \right)
\end{equation}

where $\mu_{ng}$ is defined as above.



% Single-cell data is known to exhibit \emph{dropout} where the failure to reverse-transcribe lowly expressed mRNA results in zero counts in the expression matrix. The issue has been extensively studied in the context of scRNA-seq, resulting in algorithms that take into account the resulting zero inflation such as ZIFA \cite{pierson2015zifa} or .

While incorporating zero-inflation in the likelihood leads to a less-mispecified model we must perform inference on an additional $N_0$ parameters, where $N_0$ is the number of zero measurements in the expression matrix. For single cell RNA-seq data this can be as high as 90\% of all measurements leading to a significant additional computational burden.

% Furthermore, such a dropout model assumes a per-gene dropout probability dependent on the mean latent expression though in reality the dropout probability would depend on the latent expression itself. This compromise allows us to estimate the parameter $\lambda$ by fitting for each gene the proportion of cells expressed versus the mean expression.


\section{Multiple solutions to bifurcation inference}

\begin{figure}%[!t]
	\centering
	\includegraphics[width=\textwidth]{gfx/ch4/bifurcation_solutions}
	\caption{Multiple solutions to bifurcation inference.
{\normalfont
Starting with three cell states we would like to infer a bifurcation process from one to the other two. If a single gene is upregulated in one of the states yet downregulated in the other two then clearly any state may act as the beginning of the trajectory. For example, if we start in state 1 then the gene is upregulated along state 2 and stays constant in state 3; if we start in state 2 then the gene is downregulated in states 1 \& 3; if we start in state 3 then the gene is upregulated in state 2 and remains downregulated in state 1.  However, due to the nonidentifiability this is true if we add additional genes that are upregulated in one or two of the cell states. The equivalent geometric argument is that we can build the transcriptomic profiles across all genes by spinning the figure about \textbf{B} (with possible inversion) and ``adding'' that gene. No matter how many additional genes we add, any one of the three states can act as the root state or beginning of pseudotime. Therefore, in the absence of any additional information there are always three equally valid solutions to bifurcation inference from gene expression data alone.
}
	} \label{fig:multisol}
\end{figure}

It is common in bifurcation inference methods to specify additional information aside to gene expression data alone.
For example, Wishbone requires the specification of a \emph{root} cell that signifies the beginning of pseudotime. % KC - check this requirement!
DPT also allows for the specification of a root cell or picks the furthest from a random cell if unspecified.
Monocle equivalently allows re-fitting of the pseudotimes with the constraint that one of the inferred ``states'' is the initial or root state.

We argue that such requirements are necessary due to a fundamental invariance in the gene expression of bifurcating cells. Figure \ref{fig:multisol} shows a conceptual model of three end-states (1-3) and a  gene which is expressed in one end state (2) but not the others. We can envisage three possible bifurcation routes here: state 1 is the initial state that bifurcates to 2 \& 3 ($1 \rightarrow 2,3$), or equivalently $3 \rightarrow 1,2$ or $2 \rightarrow 1,3$. If 1 or 3 is the initial state then the gene exhibits differential expression across the branches, while if we start at 2 the gene exhibits concordant expression across the branches. Note that for a bifurcation we require some genes that show differential expression between the branches and some that show concordant expression - lacking the former would give a non-branching trajectory and lacking the latter would give separate cell types.

The above reasons that in a single-gene case the initial state is indistinguishable from the gene expression alone. We can easily generalise this to the multiple-gene case due to the fact that the labels in figure \ref{fig:multisol} are statistically nonidentifiable. The equivalent geometric argument is that you can `spin' figure \ref{fig:multisol} about \textbf{B} for each gene (and optionally invert the expression to give two states of non-zero expression).

While in algorithms such as Wishbone and DPT this non-identifiability is solved by setting an initial cell or state, the equivalent in our model is the correct initialisation of the pseudotimes. Principal component analysis is applied to the data before inference and the principal component that best corresponds to the trajectory based on the expression of known genes is used to initialise the pseudotimes. Such trajectories correspond to local modes in the posterior space that are sufficiently narrow the probability of the Gibbs sampler moving to another is negligible. A future extension that would solve this non-identifiability would involve placing priors on the behaviour of certain genes across the branches, which combined with more efficient inference would pick out the `true' trajectory.


\section{Results}


\subsection{Synthetic datasets}

\subsubsection{Generating of synthetic datasets}

Synthetic datasets were generated for various simulations throughout the analysis. Rather than simply generating data from the model we attempted to create synthetic data that was as close to real single-cell data as feasible, meaning the synthetic data is severely misspecified with respect to our model. 

% The full details can be found in algorithm \ref{alg:synth} but summarise the procedure below.



% \begin{algorithm}                      % enter the algorithm environment
% %\algsetup{linenosize=\tiny}
% \scriptsize
% \caption{Generate pseudotemporally regulated bifurcating scRNA-seq data}          % give the algorithm a caption
% \label{alg:synth}                           % and a label for \ref{} commands later in the document
% \begin{algorithmic}[1]                    % enter the algorithmic environment
% \State \textbf{Data:} $G$ genes, $C$ cells, proportion of genes exhibiting transient expression $p_{\text{transient}}$
% \State \textbf{Result:} A $C \times G$ matrix of gene expression $X$, where $[X]_{cg} = x_{cg}$
% \For{$g \in 1 \ldots G$}
%   \State Sample $1 / \sigma^2_g \sim \text{Gamma(2,2)}$
%   \For{$b \in \{1,2\}$}
% 	  \State Draw $k_{gb} \sim \text{Unif(5, 10)}$
% 	  \State Draw $\phi_{g\cdot} \sim \text{Unif(5,10)}$
% 	  \State Draw $\delta_{g\cdot} \sim \text{Unif(a, b)}$ where $a = 0, b = 0.5$ if $g < G/2$ and $a=0.5, b=1$ if $G \geq G/2$
% 	  \State Set $k_{bg} \gets -k_{bg}$ with probability $\frac{1}{2}$
%   \EndFor
% \EndFor
% \For{$g \in G/2, \ldots, G$}
%     \State Set $b \gets 1 \text{ or } 2$ each with probability $\frac{1}{2}$
%     \State Set $k_{gb} \gets 0$
%     \State Set $b_0 = b' : k_{gb'} = 0, b_1 = b' : k_{gb'} \neq 0$
%     \If{$k_{b_1g} > 0$}
%       \State $\phi_{gb_0} \gets 0$
%     \Else
%       \State $\phi_{gb_0} \gets 2 \phi_{gb_1}$
%     \EndIf
% \EndFor
% \For{$c \in 1, \ldots, C$}
% \State Sample $t_c \sim \text{Unif(0,1)}$
% \State Sample $\gamma_c$ from $\{1,2\}$ each with probability $\frac{1}{2}$
%   \For{$g \in 1, \ldots, G$}
%     \State Set $\mu \gets \text{Sigmoid}(t_c, k_{g\gamma_c}, \phi_{g\gamma_c}, \delta_{g\gamma_c})$
%     \State Sample $x_{cg} \sim \text{N}(\mu, \sigma^2_g)$
%   \EndFor
% \EndFor
% \State Set $T$ as the set of randomly sampled indicies such that $|T| \approx p_{\text{transient}}G$
% \For{$t \in T$}
%   \If{$t < G/2}$
%     \State Sample $s_t \sim \text{LogNormal}(\log(0.05), 0.5)$
%     \For{$c \in 1, \ldots, C$}
%       \State $\mu \gets \text{Transient}(t_c, 0.5, s_t)$
%       \State $\mu \gets 1 - \mu$ with probability $\frac{1}{2}$
%       \State Sample $x_{ct} \sim \norm(2 \phi_{t1} \mu, \sigma_t^2)$
%     \EndFor
%   \Else
%     \State Set $b_0 = b' : k_{tb'} = 0, b_1 = b' : k_{tb'} \neq 0$
%     \State Sample $s_t \sim \text{LogNormal}(\log(0.05), 0.3)$
%     \For{$c \in 1, \ldots, C$}
%       \State $\mu \gets \text{Transient}(t_c, 0.75, s_t)$
%       \If{$k_{tb_1} < 0$}
%         \State $\mu \gets 1 - \mu$
%       \EndIf
%       \If{$\gamma_c = b_1$}
%         \State Sample $x_{ct} \sim \norm(\mu, \sigma_t^2)$
%       \EndIf
%     \EndFor
%   \EndIf
% \EndFor
% \For{$g \in 1, \ldots, G$, $c \in 1, \ldots, C$}
% \If{$x_{cg} < 0$}
%   \State Set $x_{cg} \gets 0$
% \EndIf
% \EndFor
% \end{algorithmic}
% \end{algorithm}


The first consideration is the functional form of gene expression along pseudotime. A linear assumption is fundamentally unrealistic as the gene expression cannot go to $\pm \infty$ as pseudotime progresses. Consequently we adopt sigmoidal expression across pseudotime (previously suggested in \cite{campbell2016order,campbell2016switchde} and discussed in chapters 2-3), parameterised\footnote{We depart from the previous notation here to avoid index hell when referencing multiple branches.} by the half-peak expression $\phi$, the \emph{switch-time} $\delta$ and the switch-strength $k$:
\begin{equation}\label{eq:sigmoid}
      \text{Sigmoid}(t, k, \phi, \delta)  = \frac{2 \phi}{1 + \exp(-k(t - \delta))}.
\end{equation}

%Examples of sigmoidal expression can be seen in figure \ref{fig:branch_expression}.

For half of the $G$ genes we assume the expression along the two branches is the same, thus we model common $k$, $\phi$ and $\delta$ parameters. For the second half we assume the expression diverges, and in particular for each gene $k = 0$ for one of the branches, which we can call $b_0$, and $b_1$ for the branch for which $k \neq 0$. If $k$ on the other branch is positive (ie $k_{gb_1} > 0$) then we set the half-peak expression on $b_0$ to zero, as the genes must both start at 0, and if one turns on the other must remain off (figure \ref{fig:mfa_synthetic}A).
Alternatively, if $k_{gb_1} < 0$ then the genes must begin in an \emph{on} state and switch off for cells on $b_1$ (figure \ref{fig:mfa_synthetic}B). Thus we set $\phi_{gb_0}$ to twice its original value. For any gene that shows divergent behaviour across branches we set $\delta$ to be in the second half of the trajectory. We then construct the mean, using the sigmoid function, and generate the data from a Gaussian noise model ensuring any negative values are set to zero. This gives the characteristic bifurcation pattern in PCA space as seen in figures \ref{fig:mfa_synthetic}E\&F.


\begin{figure}
	\centering
	\includegraphics[width=\textwidth]{gfx/ch4/s2_synthetic}
	\caption{Generation of synthetic data to test \texttt{mfa}. Examples of diverging monotonic behaviour across branches (\textbf{A} - \textbf{B}) and diverging transient behaviour (\textbf{C} - \textbf{D}), with resulting PCA representations coloured by both pseudotime (\textbf{E}) and branch allocation (\textbf{F}).} \label{fig:mfa_synthetic}
\end{figure}

We may also wish to generate transiently expressed genes to test the limits of the monotonicity assumptions in our model. Transient behaviour can either be across both branches or exhibit divergent behaviour (transient on one branch only). To simulate transient genes we swap out the sigmoidal mean function for a Gaussian function centred around the mid-point of the trajectory:

\begin{equation}
    \text{Transient}(t, l, s)  = \exp( - \frac{1}{2s} (t - l)^2 )
\end{equation}

We additionally ensure the behaviour is constrained to be identical on each branch at the beginning and end of the trajectory. Examples of such behaviour may be seen in figures \ref{fig:mfa_synthetic}C\&D.

If we would like to incorporate zero-inflation, we calculate a dropout probability for each measurement via $p_{ng} = \exp(-\lambda x_{ng})$, where $\lambda$ is set to a reasonable value based on observations of real datasets. Note that our model is mis-specified with respect to this as it models a per-gene dropout probability $p_g$.

\subsubsection{Performance on toy dataset}

We first demonstrate our method on a synthetic `toy' dataset of 300 bifurcating cells and 60 genes, half of which exhibit differential behaviour across the bifurcation and half of which show similar behaviour.
%A natural benefit of using a generative probabilistic model is that it can be used to generate data for testing and calibration purposes.
Our synthetically generated data is mildly mis-specified with respect to our model to demonstrate robustness when using real genomic data. For example, the generated gene behaviour across pseudotime is sigmoidal, which we have previously successfully used to model real single-cell datasets \cite{campbell2016order,campbell2016switchde}.

\begin{figure}
	\centering
	\includegraphics[width=\textwidth]{gfx/ch4/fig1_toy}
 \caption{Caption next page.}\label{fig:toy}
\end{figure}
\addtocounter{figure}{-1}
\begin{figure}
\caption{Probabilistic inference of bifurcations in synthetic data. 
\textbf{A} PCA representation of a toy dataset for 300 cells and 60 genes, coloured by the maximum aposteriori (MAP) pseudotime estimates.
\textbf{B} Equivalent representation as \textbf{(A)} colour by the MAP branch estimate.
\textbf{C} Equivalent representation showing whether each branch was assigned correctly. Due to the non-identifiability of mixture components, we map component indices from true to inferred such that the agreement is maximised.
\textbf{D} The inverse MAP estimates of $\chi$ largely identify which genes in the dataset exhibit different behaviour across the two branches.
\textbf{E} Comparison of different pseudotime inference algorithms to the ground truth pseudotime on this particular dataset. The algorithms MFA, PC1 (principal component 1), Moncole and DPT had correlations of 0.98, 0.98, 0.98, 0.99 (to 1 s.f.) respectively.
\textbf{F} The correlation of inferred pseudotimes to ground truth depending on the proportion of genes in the dataset exhibiting transient behaviour. MFA shows competitive performance up to around 40\% of genes begin transient despite an inherent linear assumption.}
\end{figure}

% PCA plots, comparison to true values and chi
Pseudotimes were inferred using Gibbs sampling for $10^5$ iterations. PCA representations of the synthetic data can be seen in figures \ref{fig:toy}A\&B showing the characteristic \emph{Y} shape associated with bifurcating data, coloured by both maximum aposteriori (MAP) pseudotime and branch assignment estimates respectively. We compared the Pearson correlation of the estimated pseudotimes to the true pseudotimes (figure \ref{fig:toy}C) for both MFA, PC1 (the first principal component of the data), Monocle and Diffusion Pseudotime, giving values of 0.98, 0.98, 0.98 and 0.99 (to 2 s.f.) respectively. Broad benchmarking of pseudotime algorithms to ``ground-truth'' data is difficult due to the inherent assumptions that are necessary about how genes expression evolves along trajectories. However, such toy examples demonstrates the consistency of multiple algorithms on our toy dataset.

\subsubsection{Impact of transient expression}

One weakness of our model is that it assumes gene expression changes as a linear function of time. This allows us to perform fast conjugate Gibbs sampling but is highly unrealistic for real data.
The synthetic data generated is based on sigmoidal changes across pseudotime, which being nonlinear is already mildly mis-specified with respect to our model.
However, genes may also exhibit transient behaviour, in which they are briefly down- or up-regulated before returning to their initial state. We sought to quantify the robustness of MFA to transient gene expression by performing extensive simulations. Specifically, we generated synthetic datasets with 0\%, 20\%, \ldots, 80\% of genes exhibiting transient expression, and inferred the pseudotimes using DPT, MFA and Monocle 2. This was repeated 20 times for each percentage of transient genes. The results can be seen in figure \ref{fig:toy}F. The performance of MFA remains competitive up to around 40\% of genes exhibiting transient expression, after which DPT and Monocle 2 perform significantly better. However, MFA is highly consistent with DPT and Monocle 2 on the two real datasets examined (figures \ref{fig:scrnaseq} \& \ref{fig:masscyto}) implying the occurrence of transient expression is limited enough in practice for the linearity assumption to be feasible.

% Hard assignment at beginning
One notable difference between MFA and existing bifurcation inference algorithms is in the pre-bifurcation branch assignment. Algorithms such as Wishbone and DPT will assign a separate branch to cells preceding the bifurcation. However, MFA will typically assign pre-bifurcation cells to one of the two branches modelled, with the other branch beginning at the bifurcation. A bifurcation process consists of two temporal processes that have a common origin but differing end points. Thus, due to non-identifiability, cells pre-bifurcation can equally be said to be on one branch with the second beginning at the bifurcation point. Importantly, no matter how we assign the branches under this regime the observed behaviour of genes as a function of both pseudotime and branch assignment will be consistent, which is necessary for biological insight.

\subsection{Benefits of modelling zero-inflation}

\begin{figure}
	\centering
	\includegraphics[width=\textwidth]{gfx/ch4/dropout}
	\caption{The effects of modelling zero-inflation. {\normalfont
\textbf{A} Zero counts observed in single-cell RNA-seq data may be attributed to either \emph{true zeros} where no mRNA of a given gene is produced in a cell, or \emph{dropout} where there is a failure to reverse-transcribe the low levels of starting material. Alternatively, a count is registered and the gene is \emph{amplified}. In theory not accounting for dropouts will reduce the accuracy of pseudotime inference - the two red counts at pseudotimes of 4 and 6 would be ordered with the blue counts. However, in practice it is impossible to distinguish between \emph{dropouts} and \emph{true zeros}.
\textbf{B} The percentage of counts with zero expression across 50 replicates for each value of $\lambda$ used in dropout simulations.
\textbf{C} The pearson correlation to true pseudotime using both the non-zero-inflated and zero-inflated variants of MFA as a function of $\lambda$ used to generate the dataset. Accounting for zero-inflation shows marginal benefits if only a small percentage counts are dropouts. However, for high dropout percentages ($>80\%$) the algorithm has to ``impute'' such a large percentage of the data that correlations to the true pseudotime reduce to near-zero.
	}} \label{fig:dropout_results}
\end{figure}

Single-cell RNA-seq data is known to exhibit \emph{dropout}, where a failure to reverse transcribe lowly-expressed mRNA results in zero counts. We have created a variant of MFA that employs an Empirical-Bayes like approach to account for such dropout (see \emph{methods}). However, a zero count for a particular gene in a particular cell may also be a \emph{true zero} where no mRNA in the cell is present.

We expect such true zeros to be useful for pseudotime inference. Figure \ref{fig:dropout_results}A shows a conceptual model where a gene is upregulated along pseudotime with two cells exhibiting dropout. The true zeros (in blue) help pseudotime inference as the low-expression implies they are at the beginning of pseudotime. However, the cells exhibiting dropout (in red) would potentially impede pseudotime inference as MFA would order them with the true zero cells at the beginning of the trajectory.

Accounting for such dropouts involves modifying the model so that zero counts are likely if the underlying latent expression is low. Therefore, the red dropout cells in figure \ref{fig:dropout_results}A would be effectively imputed (via Gibbs updates) upwards towards the mean expression line, increasing the accuracy of pseudotime inference. However, as there is no way to distinguish between true zeros and dropouts, we also ``impute'' the expression of the true zeros, which may itself decrease the accuracy of pseudotime inference.

We sought to quantify the benefits of modelling zero inflation against the drawbacks of losing the information contained in ``true zeros''. We created multiple synthetic datasets while varying the dropout parameter $\lambda \in \{0.02, 0.05, 0.1, 1, 10, \infty\}$, where $\lambda = 0.02$ has the largest levels of dropout while $\lambda = \infty$ has no dropout, only true zeros. This was repeated 50 times for each $\lambda$, and the proportion of zero counts in each dataset can be seen in figure \ref{fig:dropout_results}B. We subsequently re-inferred the pseudotimes using MFA with both the zero-inflated and standard variants.

The resulting correlations with the true pseudotimes across the range of $\lambda$ and MFA variants can be seen in figure \ref{fig:dropout_results}C. At very high levels of dropout ($\lambda = 0.02$, where $>80\%$ of counts are zeros) the zero-inflated variant performs considerably worse than the non-zero-inflated variant, with virtually no correspondence to the true pseudotimes compared to $\rho \approx 0.75$. We suggest this is due to the inference procedure effectively imputing such a large proportion of the data that there are too many degrees of freedom to effectively infer the trajectory. For the remaining values of $\lambda$ the zero-inflated variant infers pseudotimes largely comparable to those of the non-zero inflated version, with marginal improvements in accuracy when there is moderate dropout ($\lambda = 1, 10$). We conclude that incorporating zero-inflation into such pseudotime inference is possible, but the variable quality across the (unknown in practice) dropout range along with considerable additional computational cost render it unnecessary for practical purposes.

\subsection{Application to single-cell RNA-seq data}

\begin{figure}
	\centering
	\includegraphics[width=\textwidth]{gfx/ch4/scrnaseq_fig}
	\caption{Caption next page.}
	 \label{fig:scrnaseq}
\end{figure}
\addtocounter{figure}{-1}
\begin{figure}
\caption{Inference of bifurcations in scRNA-seq data of 4,423 Hematopoietic progenitor/stem cells (HSPCs) differentiating into myeloid and erythroid precursors.
\textbf{A} tSNE representation from \cite{setty2016wishbone} coloured by the maximum aposteriori (MAP) pseudotime.
\textbf{B} Equivalent plot as \textbf{A} coloured by MAP $\gamma$ (branch assignment).
\textbf{C} Inverse map $\chi$ showing both the 20 largest and 20 smallest values indicating which genes do and do not show differential behaviour across the bifurcation.
\textbf{D} tSNE representation of the dataset coloured by gene expression. Both \emph{ELANE} and \emph{CAR2} were predicted by the inverse $\chi$ values to show differing expression across the branches, while \emph{RPL26} was predicted to show similar expression.
\textbf{E} Scatter plots of pseudotime values compared to those inferred by PC2, Wishbone, Monocle, and DPT. These had pearson correlations of 0.54, 0.83, 0.01, and 0.78 respectively.
\textbf{F} tSNE representations of the dataset coloured by branch allocation of alternative algorithms shows good agreement with Wishbone and DPT.}
\end{figure}


We next applied our method to previously published single-cell RNA-seq data of 4,423 Hematopoietic progenitor/stem cells (HSPCs) differentiating into myeloid and erythroid precursors \cite{paul2015transcriptional}.
% When applying Wishbone, the authors pre-selected reduced dimension components (known as diffusion components) based on each component's association with known gene-sets. However,
% to emphasise a less supervised approach % oh the irony
To reduce the dataset to a computationally feasible size we used only genes expressed in at least 20\% of cells with a variance in normalised expression greater than 5.
We performed Gibbs sampling for $4 \times 10^4$ iterations using default hyperparameter values except for $\tau_\theta = \tau_\eta = 1$ and initialised the pseudotimes to the second principal component of the data.
The results can be seen in figure \ref{fig:scrnaseq}(A-B). The MAP pseudotime estimates  clearly recapitulates the trajectory in the data as shown using a tSNE representation from \cite{setty2016wishbone}, while the MAP estimates of $\gamma_n$ detects the branching structure in the data, consistent with previous methods.


We went on to analyse the genes suggested by the model to be involved in the bifurcation process. Figure \ref{fig:scrnaseq}C shows the inverse posterior mean of $\chi_g$, with larger values indicating more evidence that gene $g$ is involved in the bifurcation process. For illustration purposes, we plot the expression of \emph{ELANE} and \emph{CAR2}, which the model suggests will show differential behaviour across the bifurcation, along with \emph{RPL26}, which the model suggests will show common behaviour (figure \ref{fig:scrnaseq}D).

We next sought to compare the performance of MFA to existing bifurcation inference algorithms, in particular Wishbone, DPT and Monocle (v2), along with the second principal component of the data (PC2), which we noted from exploratory analyses was highly correlated with the existing Wishbone values.
We subsampled down to 1000 cells for Monocle comparisons for computational convenience and used the previously published results for Wishbone  (from \cite{setty2016wishbone}).
The root cell for DPT was selected as the cell with the minimum value for the second principal component and similarly the root state for Monocle was chosen such that it contained that cell. Otherwise, algorithms were run with default parameters.

The comparison of the inferred pseudotimes with that of MFA can be seen in figure \ref{fig:scrnaseq}E. There is high correlations with PC2 ($\rho = 0.54$), Wishbone ($\rho = 0.83$), and DPT ($\rho = 0.78$). However, there is virtually no correlation with Monocle ($\rho = 0.01$), though as this low correlation only occurs with Monocle we assume it is not an issue with MFA. We also sought to compare branch allocations across the algorithms across the algorithms which is difficult due to the non-identifiability of the statistical models involved. Figure \ref{fig:scrnaseq}F shows a tSNE representation of the cells coloured by branch allocation for each of Wishbone, Monocle and DPT. We see that MFA is largely consistent with Wishbone and DPT, detecting a bifurcation at the ``pinch'' in the tSNE plot, but as with the pseudotimes there is barely any correspondence in branch allocations with Monocle (which, as of version 2, does not allow pre-specification of the number of branches to model).

\subsection{Application to single-cell mass-cytometry data}

We next applied MFA to single-cell mass cytometry data tracking the differentiation of 22,850 monocytes and erythrocytes from hematopoietic stem and progenitor cells across 12 markers as published in \cite{bendall2011single} and previously analysed in \cite{setty2016wishbone}. For computational convenience with all algorithms we subsampled the data down to 2,000 randomly chosen cells, with the exception of Monocle which we subsequently subsampled further down to 1,000 cells. We found that due to the small number of proteins measured there was too much freedom for the MFA model to infer mixtures using the default parameter settings. We therefore had to encourage large levels of similarity across the two branches by setting $\alpha_\chi = 5 \times 10^3$ and $\beta_\chi = 1$.

The results can be seen in figure \ref{fig:masscyto}. Figure \ref{fig:masscyto}A shows a tSNE representation (as published in \cite{setty2016wishbone}) showing the inferred MAP pseudotimes correctly following the left-right trajectory, while figure \ref{fig:masscyto}B correctly shows the MAP $\gamma$ values identifying a bifurcation at the ``pinch'' in the plot.

We subsequently compared the inferred pseudotimes and branching to those found using the alternative algorithms. We found good correspondence to all other methods (figure \ref{fig:masscyto}C), with pearson correlations of 0.84, 0.86, 0.80 and 0.69 for PC2, Wishbone, Monocle, and DPT respectively. We further compared the branch assignment of MFA to those of the alternative algorithms (figure \ref{fig:masscyto}D). As of version 2, Monocle does not allow for the number of branches to be selected \emph{a priori} and typically returns a large number. For the convenience of visualisation we therefore only display the 30\% most frequent states and group the remaining infrequent ones into ``Other''. We find good agreement between MFA and Monocle and DPT, and similarities with the Monocle assignments (MFA branch 2 loosely corresponds to Monocle branch 17).

\begin{figure}
	\centering
	\includegraphics[width=\textwidth]{gfx/ch4/masscyto_fig}
	\caption{Caption next page.} \label{fig:masscyto}
\end{figure}
\addtocounter{figure}{-1}
\begin{figure}
	\caption{Inference of bifurcations in single-cell mass cytometry data of a subsample of 2,000 HPSCs differentiating into monocyte and erythrocyte progenitors.
	\textbf{A} tSNE representation from \cite{setty2016wishbone} coloured by the maximum aposteriori (MAP) pseudotime.
	\textbf{B} Equivalent plot as \textbf{A} coloured by MAP $\gamma$ (branch assignment).
	\textbf{C} Scatter plots of MFA pseudotime compared to PC2, Wishbone, Monocle, and DPT, with pearson correlations of 0.84, 0.86, 0.80 and 0.69 respectively.
	\textbf{D} tSNE representation coloured by branch assignment of Wishbone, Monocle, and DPT. As of version 2, Monocle does not allow for the number of branches to be selected \emph{a priori} and typically returns a large number. For the convenience of visualisation we therefore only display the 30\% most frequent states and group the remaining infrequent ones into ``Other''. The figures suggest a good agreement of branch assignment of MFA with Wishbone and DPT, and moderate agreement with Monocle.
	}
\end{figure}



\section{Discussion}

% What we did
In this chapter we have presented a Bayesian hierarchical mixture of factor analysers for inference of bifurcating trajectories in single-cell data. Our model is unique compared to existing efforts in that it (a) is fully generative, incorporating measurement noise into inference, (b) jointly infers both the pseudotimes and branches compared to post-hoc inference of branch detection, and (c) jointly infers which genes are differentially regulated across the branches. We also proposed an extension that accounts for the high levels of zero-inflation present in single-cell RNA-seq data. We applied our model to a range of synthetic and real datasets and demonstrated it  performs competitively with existing methods.

% Some comparisons
\subsection{Trade off between model expressivity and practicality}

There is a natural trade-off in designing such models between flexibility and practicality. The implicit assumption of MFA that gene expression develops linearly across pseudotime allows for fast MCMC sampling and joint inference of branch structure. However, it is highly mis-specified: the predicted expression can easily become negative leading to erroneous inference. A solution to this would be to not explicitly assume a strongly parametric form of gene expression and consider nonparametric methods. However, such methods are often overly flexible, requiring either additional capture information to correctly infer pseudotimes \cite{Reid2016-yo} or hard-setting the pseudotimes prior to inferring the branching structure \cite{lonnberg2016temporal}. As such there is a natural trade-off between the expressivity of such models and being able to perform valid statistical inference that fully incorporates parameter variation without additional constraints or
 \emph{tweaking}.


 % As mentioned previously, one main weakness of the model is the unrealistic assumption of linear changes in expression over pseudotime leading to severe model specification. One could therefore consider alternative nonlinear functions such as sigmoids (previously used in \cite{campbell2016ouija}) or nonparametric models such as Gaussian Process Latent Variable Models (previously used in \cite{Reid2016-yo,campbell2015bayesian}) with appropriate structural constraints.

% Future extensions

\subsection{Scalable inference}

%There are several extensions that can be applied to our model.
While our current inference procedure performs well on large single cell RNA-seq datasets there are scalable extensions that help as the number of single cells sequenced increases. The conditionally conjugate nature of the model makes it amenable to co-ordinate ascent variational inference (CAVI)\footnote{Ideas we explore further in chapter 5.}, where a variational approximation transforms inference into an optimisation procedure. Once CAVI updates have been derived, an easy next step is   stochastic variational inference (SVI, \cite{hoffman2013stochastic}), which subsamples data points for highly scalable inference. Such procedures will become necessary in single-cell statistical analysis as new technologies such as DropSeq \cite{Macosko2015-ek}
and 10x genomics \cite{eisenstein2015startups} produce expression profiles for $>\mathcal{O}(10^6)$ cells.

\subsection{Limits of linear latent variable models}

In general we expect linear latent variables to be highly mis-specified with respect to real gene expression data - gene expression will rarely evolve linearly as a function of time, nor even necessarily monotonically. A surprising result is that such an assumption is in practice sufficient to recapitulate the results on real data of algorithms that specifically account for nonlinearities in the data. We can therefore assume that the majority of genes in real datasets behave approximately linearly.

\begin{figure}
	\centering
	\includegraphics[width=\textwidth]{gfx/ch4/limits_of_chi}
	\caption{The limits of linear latent variable models for inferring bifurcations from
	single-cell data. \emph{CD11b} is correctly identified as exhibiting bifurcating behaviour.
	However, due to model mis-specification the cells with nonzero expression are assigned to branch 2, when in fact they should be assigned to both branches 1 \& 2, meaning \emph{CD34} is incorrectly identified as differentially regulated across the bifurcation.} \label{fig:chi}
\end{figure}

Such mis-specification - though conducive to fast full MCMC inference - does come at a cost. An example is given in figure \ref{fig:chi} of the mass cytometry data presented in the main text (we have reversed the pseudotimes so time runs from left to right). The gene \emph{CD11b} displays differential regulation across the branches - up-regulation on branch 1 and constant expression on branch 2. The model fits two values of $k$ for this as can be seen by the black line fits, and this the value of $\chi$ is sufficiently small that we correctly designate it as a gene that bifurcates.

However, the gene \emph{CD34} is incorrectly designated as one that should bifurcate when in fact it doesn't. Due to model mis-specification the cells with non-zero expression at the beginning are ``hard-assigned'' to branch 2, when in fact they should be equally assigned to both branches 1 \& 2. Consequently, $|k_2| \gg |k_1|$ and the value of $\chi$ indicates that the gene is involved in the bifurcation, when in fact it isn't. Such incorrect inferences can easily be checked visually on a reduced-dimension representation.

\subsection{Choosing the number of branches}

A further limitation of our model is the requirement to specify the number of branches $B$ \emph{a priori}. While at time of writing no single-cell datasets are known to have more than a single bifurcation point, the increasing resolution of single-cell technologies make such situations likely in the future. Here we propose two extensions for selecting the number of branches, by viewing it as a model selection problem or by modifying the model to be a nonparametric (i.e. infinite) mixture of factor analysers.

\subsubsection{As a model selection problem}

One method to choose the number of branches is to construct a finite set of (non-zero) integers and choose the number that best explains the data by some measure. We can view this as the classic Bayesian model selection problem where we wish to compute the marginal likelihood of the data given a pre-specified number of branches.

Without loss of generality consider two numbers of branches, $B_1$ and $B_2$. We can compute the marginal likelihood of the data $\bY$ given the number of branches $B$ via

\begin{equation}
	p(\bY | B) = \int_{\bm \Theta} p(\bY | \bm \Theta, B) p (\bm \Theta | B) d \bm\Theta
\end{equation}

where $\bm \Theta$ is the entire set of model parameters. We then compute the \emph{Bayes factor} comparing the two branches $B_1$ and $B_2$ as

\begin{equation}
	\text{Bayes factor} = \frac{p(\bY | B_1)}{p(\bY | B_2)}
\end{equation}

which provides the relative evidence for $B_1$ over $B_2$.

\subsubsection{Nonparametric mixture of factor analysers}

An alternative approach to choosing the number of branches would be to use a nonparametric mixture of factor analysers through the use of dirichlet process (DP) priors on the loading matrix. To define a DP we require a \emph{base distribution} $H$ defined on $\mbtheta$ and a positive number $\alpha$. Then $G$ is a DP ($G \sim \text{DP}(\alpha, H)$) if for any finite partition 
$\theta_1, \ldots, \theta_n$ of $\mbtheta$ we have 
\begin{equation}(G(\theta_1), \ldots, G\left(\theta_n)\right) \sim \text{Dirichlet}(\alpha H(\theta_1), \ldots, \alpha H(\theta_n)).\end{equation} 

DPs can easily be sampled from by drawing a sample $x_1$ from the base distribution $H$ and for the remaining $2, \ldots, N$ samples resampling from $H$ with probability $\frac{\alpha}{\alpha + n - 1}$ and sampling $x_n$ from the existing $x_1, \ldots, x_{n-1}$ otherwise. In other words, $\alpha$ can be thought of as controlling the probability of adding a new value, which in the case of a mixture of factor analysers would add an additional branch. An example draws of a DP for a standard normal distribution for varying values of $\alpha$ can be seen in figure \ref{fig:dp}.

\begin{figure}
	\centering
	\includegraphics[width=\textwidth]{gfx/ch4/dp_sn_base_dist.png}
	\caption{100 draws from a dirichlet process with $\alpha = 0.5, 1, 2, 5$ with a standard normal base distribution.} \label{fig:dp}
\end{figure}

Nonparametric mixtures of factor analysers have previously been considered for compressed sensing \cite{chen2010compressive} and applied to NMR metabolomic data \cite{murphy2017infinite}. Such models typically consider a nonparametric prior on the number of latent dimensions allowing the model to ``automatically decide'' the dimensionality of the latent space, though in pseudotemporal applications this can be fixed to 1. A nonparametric mixture of overlapping Gaussian Processes was considered in \cite{lonnberg2016temporal}, though they found that in practice this typically overestimated the number of branches.

The use of DP priors in this context has other drawbacks too. Though often sold as ``inferring the number of components [of a mixture model] automatically'' there is still the requirement to tune the parameter $\alpha$ that affects the eventual number of components. Furthermore, it is known that DP mixture models typically overestimate the number of components and are in fact inconsistent for the number of components \cite{miller2013simple}. In other words, even if we had an infinite amount of data a DP mixture model will not estimate the correct number of mixture components. Therefore, other approaches (such as model selection above) may be more suitable for inferring the number of branches in such settings.

\subsection{Accounting for technical effects}

Single-cell RNA-seq data are known to substantially suffer from technical batch effects \cite{tung2017batch,hicks2017missing}, particularly if multiple cells are sequenced across different plates or microfluidic devices. To account for this our model could be modified to take the form of a linear mixed model as

\begin{equation}
	\mby_n = \mbalpha x_n + \mbc_{\gamma_n} + \mbk_{\gamma_n} t_n + \mbepsilon_n
\end{equation}

where $x_n$ indicates to which batch cell $n$ belongs and $\mbalpha$ is a vector of gene-specific intercepts that account for global expression shifts due to technical effects.
