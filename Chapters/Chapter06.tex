%************************************************
\chapter{Conclusion}\label{ch:conclusionchap} % $\mathbb{ZNR}$
%************************************************

In this thesis we have considered inferring ``trajectories'' through gene expression space as a statistical latent variable problem. Such an approach is feasible when the data is gene expression from single-cells that undergo a physical time process where it is difficult to truly measure time and population-level cancer studies where such trajectories correspond to the activation of biological pathways. 

As such quantities are estimated from noisy biological data it is important that a full probabilistic treatment taking uncertainty into account is considered as this has a large impact on downstream differential expression testing. We further demonstrated that contrary to existing approaches, which typically employ dimensionality reduction and cell ordering steps, it is possible to learn pseudotimes from a small set of marker genes using a simple parametric model. In such settings if the genes exhibit ``switch-like'' changes in expression over pseudotime then encoding this information as informative Bayesian priors typically improves inference.

We further considered the case of bifurcations in single-cell data, where cells proceed along some developmental trajectory before undergoing a fate decision that leads to two or more possible outcomes. All existing approaches to date treat this as a two step procedure that first learn a pseudotime for each cell then identify branching post-hoc assuming the pseudotimes are fixed. This has obvious issues in terms of treating the pseudotimes as fixed quantities and assumes the major source of variation comes from the pseudotemporal progress rather than the branch structure. We proposed that a Bayesian mixture of factor analysers is a solution to jointly generatively model both the trajectory and bifurcation event. By imposing a unique hierarchical structure between the loading matrices of each mixture we were able to automatically identify genes that bifurcated, though this was limited to an extent by the linear assumptions of the model.

Finally we considered the case where such trajectories exist against a heterogeneous genetic or environmental background. We proposed a novel type of latent variable model that allows the behaviour of features to vary along the trajectory differently depending on some externally measured quantity, such as mutational burden or stimulant exposure. We further applied this to population wide cancer gene expression data, demonstrating that such ``trajectories'' correspond to biological pathway activation and identified interactions between such pathways and externally measured covariates. A fast variational inference algorithm was derived in order to infer such trajectories and interactions for thousands of genes and samples relatively quickly. We further proposed an extension for the case that the externally measured covariate is a possibly-censored survival time. Finally, we derived a non-parametric extension termed a covariate-adjusted Gaussian process latent variable model and demonstrated its utility on some synthetic data.

There are several ideas to be considered that form extensions to this work and the basis for new research. A major theme in our discussions so far and indeed among the current single-cell community is scaling up inference. This is particularly pertinent as new technologies such as Drop-seq and 10x genomics scale up sequencing to hundreds of thousands and millions of cells\footnote{
   Gone are the early-PhD days of emailing yourself a single-cell dataset and pretending to everyone else that you work on ``Big Data''.
}. 

A major advantage of phrasing the pseudotime estimation problem as a (Bayesian) statistical latent variable one is that once we have written down a model we can ``borrow'' scalable inference procedures from elsewhere in the field. This is in contrast to what you could term the more algorithmic approach to pseudotime inference - that often relies on some tree or graph-building procedure - where a hand-crafted computational considerations are required for each algorithm and modification.

An obvious future direction for such research is to construct Bayesian models that use (black-box) variational inference\footnote{
    To quote David Blei, ``Variational inference is that thing you implement while waiting for your Gibbs sampler to converge.''
} and stochastic variational inference (SVI). The major advantage behind SVI is that it can subsample observations typically in batches in order to climb noisy estimates of the ELBO, meaning it scales well as we vastly increase the number of cells in our datasets. An interesting observation is that statistical modelling of gene expression has typically been a $P \gg N$ problem, as we have $P \approx 20,000$ genes but $N \sim \mathcal{O}(10)$ samples. However, as the single-cell library preparation technology improved, we now face the opposite situation: $P$ will always be fixed\footnote{
Alternatively if you look at expression of individual transcripts rather than genes then $P \approx 170,000$ but as before this is fundamentally fixed.
} at $\approx 20,000$, while $N$ is  unbounded in practice.

The scalability issue becomes worse if we work with Gaussian processes, where just evaluating the likelihood requires an expensive $\mathcal{O}(N^3)$ matrix inversion. A promising future direction in the field would then look at scalable inference for GPs in single-cell transcriptomics using techniques such as inducing points.

A prominent theme running through chapters 2 to 4   is the idea of \emph{a priori} smoothness assumptions and model flexibility. %A GPLVM with no constraints is fundamentally underdefined (or overly flexible) and can jump between local maxima as valid trajectories. 
Several methods have been proposed to overcome this, such as strong priors on the kernel parameters or priors in the latent space centred around physical capture times. On the other hand, we have shown that it's possible to learn such trajectories by making strongly parametric assumptions about how gene expression that require no tuning but are limited in the gene behaviour the can model (under this framework we cannot model transient expression). Therefore, there is a natural trade-off between model expressivity and practicality / accuracy. This opens several exciting research avenues: for example, is it possible to constrain the parameters of a GPLVM in terms of the expected number of fluctuations over pseudotime? Can we impose additional structural constraints on GPLVMs through kernel design such as enforcing monotonicity or other interpretable gene behaviour?

A more theoretical avenue to be explored is the connection between existing ``algorithmic'' approaches (dimensionality reduction followed by MST fitting) to latent variable approaches such as nonlinear factor analysis and GPLVM. MST based approaches such as Monocle and TSCAN find the longest single path through the MST in the reduced space. Intuitively, this should be \emph{very} similar to the first principal component of the data\footnote{
    Indeed the output of many pseudotime algorithms is extremely similar to PC1.
} as we find a one dimensional path through a maximal number of data points that is similar to finding a one dimensional projection that maximises the variance in the reduced space. Indeed, if the initial dimensionality reduction is linear (as is often a case), then the only nonlinearity induced will be by the longest path through the MST curving back on itself, which is very rare. Therefore we can conclude that ordering cells using MSTs in linear dimensionality reduction spaces will be very similar to principal component analysis.

A future research area related to single-cell trajectories that has the potential to become popular is unsupervised multiview learning. As it becomes feasible to make multiple ``omic'' measurements alongside expression from a single-cell at once - such as epigenetic modifications and DNA sequence - we should in theory be able to learn pseudotimes from the different data sources simultaneously and improve inference as a result. Such models would include a common underlying pseudotime $z_n$ for each cell but could model a different likelihood $L_d(\mbX_d | \mbz, \mbtheta_d)$ for each $d = 1, \ldots, D$ data source. The challenge here is showing what you might gain from modelling more than one data source simultaneously as ultimately if they follow a common trajectory the sources are likely to be heavily correlated.

Finally, there is a paradox that runs through the entire single-cell pseudotime field. It is impossible to truly benchmark such algorithms because current technology cannot track a single-cell over time while performing transcriptome-wide gene expression quantification. This has led researchers to use a variety of heuristics such as smoothness criteria or consistency with capture times\footnote{
    Though this is dubious since the whole point behind pseudotime algorithms is that the cells progress asynchronously meaning capture times do not reflect true biological progress.
} to compare their algorithms to others. However, the moment we develop transcriptome-wide time series expression measurement technology pseudotime will no longer be required as we will have something infinitely better - real time. In other words, as soon as we are able to correctly benchmark and compare such algorithms we have rendered them obsolete.

%*****************************************
%*****************************************
%*****************************************
%*****************************************
%*****************************************
