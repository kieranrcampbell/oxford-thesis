%************************************************
\chapter{Covariate-adjusted latent variable models}\label{ch:phenotimechap} % $\mathbb{ZNR}$
%************************************************


%*****************************************
%*****************************************
%*****************************************
%*****************************************
%*****************************************

\section{Introduction}

\begin{figure}
\centering
  \includegraphics[width=0.98\textwidth]{gfx/ch5/1_method_diagram}
  \caption{The behaviour of gene expression along trajectories may be affected by externally measured covariates.
  Such covariates may be discrete (left) or continuous (right).
  } \label{fig:phenotime_diagram}
\end{figure}

So far in this thesis - and indeed in all published pseudotime algorithms to date - we have assumed that all cells or samples evolve along each trajectory identically. However, this assumption could easily be violated. For example, gene expression may change along the trajectory in a manner dependent on a cell's genetic background or perhaps upon a stimulant the cell has been exposed to.

The intuition for this problem is shown in figure \ref{fig:phenotime_diagram}. We can imagine the association between gene expression and the latent trajectory dependending on some additional covariate (here given by the colour of the line). In the case of ``red'' samples, expression increases along the trajectory, while in the case of blue samples expression decreases. The same idea can easily be extended to the case in which the covariate is continuous.

Applying current pseudotime algorithms to such situations would confound inference. In the example in figure \ref{fig:phenotime_diagram} there is no change in gene expression along the trajectory if the covariate is ignored, meaning there is no information contained in the gene that could be used to infer the trajectory unless the covariate is somehow incorporated. Furthermore, such interactions would not exist for all genes, so it would be advantageous if a model could pick out these interactions as they would be informative of the underlying biology.

As a solution to such issues this chapter introduces a general class of statistical models termed \emph{covariate-adjusted latent variable models} that allows an externally measured set of covariates to perturb the change of features along the latent space. We proceed by deriving a scalable variational inference algorithm for inferring such models and their interactions. This is applied to single-cell expression data in section \ref{sec:shalek} but also bulk RNA-seq data in sections \ref{sec:coad} and \ref{sec:brca}, where we show that such trajectories correspond to the activation of biological pathways. Next, the case of the external covariate being a censored survival time is considered, with an application to population-level breast cancer studies. Finally, a non-parameteric extension similar to GPLVM - termed \emph{Covariate-adjusted Gaussian Process Latent Variable Models} - is proposed.

This chapter includes a minor change in notation - latent variables are now $z_n$ rather than $t_n$ as they may no longer represent physical time processes but more abstract notions of biological pathway activation.

\section{Covariate-adjusted latent variable models}

\subsection{Statistical model}

\begin{figure}
\centering
  \includegraphics[width=0.98\textwidth]{gfx/ch5/2_phenopath_eqn}
  \caption{PhenoPath models observed expression as a combination of standard differential expression (DE) and pathway effects, including covariate-pathway interactions.
  } \label{fig:phenopath_eqn}
\end{figure}

We begin as usual with an $N \times G$ matrix of gene expression $\mbY$ with row vectors $\mby_n$ for $N$ samples and $G$ genes. A standard factor analysis model would infer a $Q$-dimensional embedding $\mbz_n$ for each sample $n = 1, \ldots, N$ where $Q \ll G$ via a model of the form

\begin{equation}
  \begin{aligned}
\mbz_n & \sim \Norm(0, \mbI) \\
\mby_n & \sim \Norm(\mbLambda \mbz_n, \mbSigma)
  \end{aligned}
\end{equation}

where $\mbLambda$ is a $G \times Q$ factor loading matrix with column vectors $\mblambda_q$ and $\mbSigma = \text{diag}(\sigma_1^2, \ldots, \sigma_G^2)$ is a diagonal covariance matrix of measurement noise. As noted before, if $Q = 1$ then $z_n$ can be interpreted as the ``pseudotime'' of each cell in which case the factor loading matrix becomes a $G-$length factor loading vector $\mblambda$ and the likelihood of $\mby_n$ becomes $\mby_n  \sim \Norm(\mblambda z_n, \mbSigma)$.

We now consider the case mentioned in the introduction that we have an $N \times P$ matrix $\mbX$ that represents $P$ covariates for each of the $N$ samples. In a population wide study such covariates might represent phenotypic variables such as age or sex, while in a single-cell setting such covariates might represent genetic background or cell stimulus.

We would like these covariates to perturb the change in expression of each gene along the trajectory. To do this we introduce an additional $G \times P$ matrix $\mbB$ whose entries $\beta_{pg}$ represent the effect of covariate $p$ on the change of gene $g$ along the trajectory. Thus the factor loading for gene $g$ becomes

\begin{equation}
  \lambda_g \rightarrow \lambda_{ng}' = \lambda_g + \sum_{p=1}^P \beta_{pg} x_{np}
\end{equation}

or in vector notation  $\mblambda \rightarrow \mblambda'_n = \mblambda + \mbB \mbx_n$. In other words, each sample has a unique loading for each gene that depends on a common loading vector $\mblambda$ and modulation by the sample-specific covariates.

In factor analysis models it is typical to standardize the data so that the marginal mean is 0 which simultaneously enforces the constraint $y=0$ when $z=0$. However in this case that constrains the data to ``swing'' around the origin based on the covariate which is overly restrictive. To solve this we introduce an additional $N \times P$ matrix $\mbA$ whose entries $\alpha_{pg}$ account for the global shift in expression of gene $g$ in response to covariate $p$. Therefore, the generative \emph{covariate-adjusted latent variable model} takes the form

\begin{equation}
  \begin{aligned}
\mbz_n & \sim \Norm(0, \mbI) \\
\mby_n & \sim \Norm\left( \mbA \mbx_n + (\mblambda + \mbB \mbx_n) z_n, \mbSigma\right)
  \end{aligned} \label{eq:clvm}
\end{equation}

In a genomics context $\alpha_{pg}$ can be thought of as mediating differential expression (figure \ref{fig:phenopath_eqn}) while $\mblambda$ can be thought of as the change in expression along the latent trajectory regardless of covariates. Note that if we multiply out the bracket in \ref{eq:clvm} we see that this is a form of linear mixed model with interactions between the random and fixed effects, though to our knowledge such a model has not been proposed before.

In practice we restrict ourselves to $Q=1$ dimensional latent spaces (that roughly correspond to ``pseudotimes'' or ``trajectories''). However, this can be readily extended to the $Q>1$ case by making $\mbB$ a $Q \times P \times G$ factor loading tensor\footnote{
Technically an array rather than a tensor in the true sense.
} whose entries $\beta_{qpg}$ quantify the interaction between covariate $p$ and gene $g$ in latent dimension $q$. The mean $\mu_{ng}$ for observation $y_{ng}$ is then given by

\begin{equation}
  \mu_{ng} = \sum_{q=1}^Q \left(
  \lambda_{qg} z_{nq} + \sum_{p=1}^P (\alpha_{qpg} x_{np} + \beta_{qpg} x_{np} z_{nq})
  \right)
\end{equation}

In general we expect trajectory-covariate interactions to be rare we place an automatic relevance determination (ARD) prior on them (previously discussed in chapter 4).
In the $Q=1$ dimensional case this takes the form $\beta_{g} \sim \Norm(0, \chi_g^{-1})$, $\chi_g \stackrel{iid}{\sim} \Gam(a_\beta, b_\beta)$. We set $a_\beta = b_\beta = 0.01$ which places the prior precision close to zero but has high variance. The overall generative model then takes the form

\begin{equation}
\begin{aligned}
\alpha_{pg} & \sim \norm(0, \tau_\alpha^{-1}) \\
\lambda_g & \sim \norm(0, \tau_\lambda^{-1}) \\
z_n & \sim \norm(q_n, \tau_q^{-1}) \\
\beta_{pg} & \sim \norm(0, \chi_{pg}^{-1}) \\
\chi_{pg}^{-1} & \sim \text{Gamma}(a_\beta, b_\beta) \\
\tau_{g}^{-1} & \sim \text{Gamma}(a, b) \\
%\mu_{g} & \sim \norm(0, \tau_\mu^{-1}) \\
\epsilon_{ng} & \sim \norm(0, \tau_g^{-1}) \\
y_{ng} & = \mu_g +  \sum_p \alpha_{pg} x_{np} + \left( \lambda_g + \sum_p \beta_{pg} x_{np} \right) z_n + \epsilon_{ig}
\end{aligned} \label{eq:clvm_model}
\end{equation}

where $\tau_\alpha$, $\tau_\lambda$, $a$, $b$, $a_\beta$, $b_\beta$, $\tau_q$ are fixed hyperparameters and $q_n$ encodes prior information about $z_n$ if available but typically $q_n = 0 \; \forall n$ in the uninformative case.



\subsection{Inference}

\subsubsection{Gibbs sampling}

The conditionally conjugate nature of the model in equation \ref{eq:clvm_model} makes Gibbs sampling once more possible, as was explored in section \ref{sec:gibbs}. The Gibbs updates for this are given in appendix \ref{app:clvm_gibbs}. However, Gibbs sampling becomes slow as the number of parameters increases, which needs particular care in this model given the number of parameters scales as $G \times P$ for $G$ genes and $P$ covariates.

\subsubsection{Co-ordinate ascent variational inference}

Instead we turn to variational inference which recasts Bayesian inference as an optimisation problem, rather than the sampling approaches previously used. Below, variational inference is briefly introduced along with the strategy for deriving updates for covariate-adjusted latent variable models, which may be found in \ref{app:clvm_vi}.

In general Bayesian inference is concerned with inferring the posterior distribution $p(\mbtheta | \mbX) = \frac{p(\mbX | \mbtheta) p(\mbtheta)}{p(\mbX)}$ for some parameters $\mbTheta$ and data $\mbX$. This is difficult in general as the marginal likelihood $p(\mbX)$ is often intractable and hard to compute.

Variational inference posits an approximating or \emph{variational} distribution $q(\mbtheta | \mblambda)$ with variational parameters $\mblambda$ and the objective of inference is to choose optimal $\mblambda$ so that $q(\mbtheta | \mblambda)$ is as ``close'' to $p(\mbtheta | \mbX)$ as possible. This closeness is normally definied with respect to some divergence measure such as the Kullback-Leibler (KL) divergence which is a measure of the non-symmetric difference between two probability distributions. Thus Bayesian inference is transformed into an optimisation procedure that attempts to minimise

\begin{equation}
  \KL{q(\mbtheta | \mblambda)}{p(\mbtheta | \mbX)} =
  \int d\mbtheta q(\mbtheta | \mblambda) \log\left[ \frac{q(\mbtheta | \mblambda)}{p(\mbtheta | \mbX)}\right].
\label{eq:kl_min}
\end{equation}

A little algebra shows that minimising the $KL$-divergence in equation \ref{eq:kl_min} is equivalent to maximising the evidence lower-bound (ELBO), defined as

\begin{equation}
  \text{ELBO}(\mblambda; \mbX, \mbtheta) = \mbE_{q(\mbtheta | \mblambda)} \left[
\log q(\mbtheta | \mblambda) - \log p(\mbX, \mbtheta)
  \right].
\end{equation}

Interestingly, because $\KL{q}{p} \geq 0$ for any $q$ and $p$ it is easy to show that the ELBO acts as a lower bound on the log marginal likelihood, i.e. $\log p(\mbX) \geq \text{ELBO}(\mblambda; \mbX, \mbtheta)$. Therefore, variational inference can be viewed either as choosing $\mblambda$ so that $q$ is as similar to $p$ as possible, or as choosing $\mblambda$ so that a lower bound on the marginal likelihood is maximised.

For our model in equation \ref{eq:clvm_model} we make what is known as a mean-field variational approximation where the variational approximation factorises across all the parameters so $q(\mbtheta | \mblambda) = \prod_i q(\theta_i | \lambda_i)$. For co-ordinate ascent variational inference the approximating distributions should be of the family as each conditional distribution. The variational distribution for our model is therefore given by

\begin{equation}
\begin{aligned}
& q\left(
\{ z_n \}_{n=1}^N,
\{ \mu_g \}_{g=1}^G,
\{ \tau_g \}_{g=1}^G,
\{ \lambda_g \}_{g=1}^G,
\{ \alpha_{pg} \}_{g=1,p=1}^{G,P}
\{ \beta_{pg} \}_{g=1,p=1}^{G,P}
\{ \chi_{pg} \}_{g=1,p=1}^{G,P}
\right) \\
& = \prod_{n=1}^N \underbrace{q_z(z_n)}_{\text{Normal}}
\prod_{g=1}^G \underbrace{q_\mu(\mu_g)}_{\text{Normal}}
\underbrace{q_\tau(\tau_g)}_{\text{Gamma}} \underbrace{q_\lambda(\lambda_g)}_{\text{Normal}}
\prod_{p=1}^P \underbrace{q_\alpha (\alpha_{pg})}_{\text{Normal}}
\underbrace{q_\beta(\beta_{pg})}_{\text{Normal}} \underbrace{q_\chi (\chi_{pg})}_{\text{Gamma}}
\end{aligned} \ref{eq:variational}
\end{equation}

For conditionally conjugate models it is possible to derive updates that maximise the ELBO for each parameter, conditioned on all other parameters being held constant. For a general model let $\theta_j$ denote the $j^{\text{th}}$ parameter and  $\mbtheta_{-j}$ the vector of all parameters other than $j$. The update that provides the distribution for $\theta_j$ that maximises the ELBO is given by

\begin{equation}
q^*_j(\theta_j) \propto \exp \left\{  \mbE_{-j} \left[ \log p(\theta_j | \mbtheta_{-j}, \mbY) \right]
 \right\},
\end{equation}

where the expectation is taken with respect to the approximating distributions for all parameters other than $j$. Successively computing updates for each variable until the change in the ELBO falls below some pre-set threshold is known as co-ordinate ascent variational inference (CAVI). In our model all parameters have conditional distributions that are either normally distributed or gamma distributed. We can derive general updates for these two cases and the specific updates may be found in appendix \ref{app:clvm_vi}.

Suppose $p(\theta_j | \theta_{-j}, \mbX) \sim \norm(\mu_{\theta_j}, \tau_{\theta_j}^{-1})$ where both the mean and precision  are dependent on the conditioning variables $\mbtheta_{-j}$ and the data $\mbX$. It follows that

\begin{equation}
q(\theta_j) = \norm\left(
\theta_j |
m_{\theta_j} = \frac{\text{E}_{-j}[\mu_{\theta_j} \tau_{\theta_j}]}{\text{E}_{-j}[\tau_{\theta_j}]},
s_{\theta_j}^2 = \text{E}_{-j}[\tau_{\theta_j}]^{-1}
\right)
\end{equation}

where the expectations are computed with respect to the variational distributions in \ref{eq:variational}.

If instead $p(\theta_j | \theta_{-j}, \mbX) = \text{Gamma}(\theta_j | a_{\theta_j}, b_{\theta_j})$ where again $a_{\theta_j}$ and $b_{\theta_j}$ are functions of the data $\mbX$ and all parameters other than $\theta_j$, then the CAVI update 	is given by

\begin{equation}
q(\theta_j) = \text{Gamma}\left(
\theta_j |
\text{E}_{-j}[a_{\theta_j}], \text{E}_{-j}[b_{\theta_j}]
\right).
\end{equation}


Variational inference for non-conditionally conjugate models is considered in \ref{sec:survival}.

\subsection{Bayesian significance testing of interactions}

It is possible to construct a Bayesian significance test for the existence of covariate-pathway interactions (in other words, whether $\beta_g$ is ``significant'' under some criterion) using posterior credible intervals and a region of practical interest. The variational approximation for each $\beta_g$ is given by $q(\beta_g) \sim \Norm(m_{\beta_g}, s^2_{\beta_g})$. Therefore, if $\hat{m}_{\beta_g}$ and $\hat{s}_{\beta_g}$ are the estimates of $m_{\beta_g}$ and $s_{\beta_g}$ respectively after a sufficient number of iterations that we consider the ELBO to be converged, then we define $g$ to have a \emph{significant interaction}
if

\begin{equation}
  | \hat{m}_{\beta_g} - k \hat{s}_{\beta_g} | > 0
\end{equation}

for some $k$. In other words, $g$ is significant if the $k \hat{s}_{\beta_g}$ posterior interval of $\beta_g$ falls outside of zero.  In practice, minimising the $\KL{q}{p}$ divergence typically underestimates posterior variances \citep{blei2016variational} so we choose a conservative $k=3$.

\subsection{Benchmarking through simulations}

\begin{figure}
\centering
  \includegraphics[width=0.98\textwidth]{gfx/ch5/3_simulation_scenarios}
   \caption{Four gene expression simulation scenarios were used: (1) differential expression only where the overall expression level for groups -1 and 1 differed but there is no dependence on pseudotime or pathway score, (2) pseudotime regulation only where the overall marginal distribution of expression values is identical between groups but expression changes with latent pathway score, (3) pseduotime and covariate interactions where the trajectory for each group differs over pathway score and (4) a complex scenario where differential expression and covariate-pseudotime interactions all exist. } \label{fig:simulation_scenarios}
\end{figure}

We first performed a simulation study to demonstrate the value of modelling covariate-pathway interactions and to show that such effects are missed by standard differential expression analyses. Specifically, we sought to compare differentially expressed genes identified by Limma Voom \cite{Law2014-tu}, one of the leading RNA-seq differential expression methods, to the $\beta$ interactions from PhenoPath. For $N = 200$ samples we assigned each to one of two categories given by the $x$ values $x = -1, 1$, and assigned a pseudotime $z$ through draws from a standard normal distribution. For each sample $n = 1, \ldots, N$ and gene $g = 1, \ldots, G$ we then generated a mean value through the PhenoPath mean function
\begin{equation}
  \mu_{ng} = \alpha_g x_n + (\lambda_g + \beta_g x_n) z_n
\end{equation}

The gene-specific parameters $(\alpha_g, \lambda_g, \beta_g)$ were sampled in equal proportions from one of four classes (figure \ref{fig:simulation_scenarios}):
\begin{enumerate}
  \item \emph{Differential expression only} where $\alpha_g = 1$ or -1 with equal probability and $\lambda_g = \beta_g = 0$
  \item \emph{Pseudotime regulation only} where $\lambda_g = 1$ or -1 with equal probability and $\alpha_g = \beta_g = 0$
  \item \emph{Pseudotime and covariate interactions} where $\lambda_g$ and $\beta_g$ are set to 1 or -1  with equal probability and $\alpha_g = 0$
  \item \emph{Differential expression, pseudotime and covariate interactions} where all parameters take on values of -1 or 1 with equal probabilities
\end{enumerate}

In order to generate RNA-seq reads we need positive count values. In the spirit of general linear models, we then used $g(x) = 2^x$ as a link function and generated a matrix of positive means
\begin{equation}
  \tilde{\mu}_{ng} = 2^{\mu_{ng}}
\end{equation}

We subsequently simulated a count matrix $c_{ng}$ by sampling for each entry from a negative binomial distribution with mean $\tilde{\mu}_{ng}$ and size parameter $\tilde{\mu}_{ng} / 3$. While this could be used as input to PhenoPath (suitable log transformed), we sought to make our simulation as realistic as possible including quantification errors. We subsequently simulated FASTA files using the Bioconductor package \texttt{polyester} \cite{Frazee2015-vy} using the first 400 transcripts of the reference transcriptome of the 22nd human chromosome. FASTA files were then converted to FASTQ files
%using a script copied from StackOverflow
and quantified into TPM and count estimates using Kallisto \cite{Bray2016-uh}. The $\log_2(\text{TPM} + 1)$ values were then used for input to PhenoPath while the raw count values were used for input to Limma Voom.


\begin{figure}
\centering
  \includegraphics[width=0.98\textwidth]{gfx/ch5/4_simulation_pca}
  \caption{Simulations of RNA-seq data with covariate pseudotime interactions for 200 samples and 400 genes using the R/Bioconductor package \texttt{polyester}. \textbf{A} A PCA representation of the data coloured by pseudotime shows a clear splitting of trajectories between covariate status.\textbf{B} Comparison of the true pseudotime to both PC1 and PhenoPath pathway score$z$ with correlations of 0.85 and 0.97 respectively.
  } \label{fig:simulation_pca}
\end{figure}


An exploratory PCA analysis of the data reveals a \emph{wishbone}-like pattern similar to bifurcations (figure \ref{fig:simulation_pca}A). Given the first principal component of the data is often a good estimator of a one-dimensional trajectory, we compared PC1 to the true pseudotimes (figure \ref{fig:simulation_pca}A). This demonstrates that the distinct phenotypic or covariate classes do confound inference of the trajectory as PC1 has a Spearman correlation of $\rho = 0.85$ with the true values compared to $\rho = 0.97$ with inference from our model when the covariates are explicitly taken into account.

% We sought to compare the performance of Limma Voom and PhenoPath in detecting differential expression and pathway interaction effects respectively, and show that there are pathway interaction effects not evident from differential expression analyses alone. We found that PhenoPath identifies such interactions with high precision (main text and Table \ref{tbl:fdr}).

\begin{table}[!t]
\begin{center}
    \begin{tabular}{ | l | c  c  c |}
    \hline
    Algorithm & True positive rate & False positive rate & False discovery rate \\ \hline
    Limma Voom & 0.82 & 0.09 & 0.18 \\
    PhenoPath & 0.97 & 0.02 & 0.03 \\
    \hline
  \end{tabular}
\end{center} \caption{A comparison of true positive, false positive, and false discovery rates for Limma Voom detecting differential expression and PhenoPath detecting covariate-pseudotime interactions on synthetic data.} \label{tbl:fdr}
\end{table}

% latex table generated in R 3.3.1 by xtable 1.8-2 package
% Wed Apr 12 14:35:33 2017
\begin{table}[ht]
\centering
\begin{tabular}{|l | c|}
  \hline
  Algorithm(s) & n \\
  \hline
 Both &  47 \\
   PhenoPath only &  16 \\
   Limma only &  12 \\
   Neither &  25 \\
   \hline
\end{tabular} \caption{Number of interactions discovered as significant under the \emph{Differential expression, pseudotime and covariate interactions} regime.} \label{tbl:nclvm}
\end{table}

\begin{figure}
\centering
  \includegraphics[width=0.98\textwidth]{gfx/ch5/5_simulations}
  \caption{A comparison of the effect sizes and number of genes identified as differentially regulated across the four simulation regimes for both Limma Voom (top) and PhenoPath (bottom). } \label{fig:simulations}
\end{figure}

%  We simulated RNAseq-based gene expression data\cite{Frazee2015-vy} where genes were either (1) differentially expressed, (2) modulated along a hidden pathway trajectory, (3) modulated along a pathway with covariate interactions, or (4) differentially expressed with pathway modulation and covariate interactions (Supplementary Figure \ref{fig:simulation_pca}, \ref{fig:simulation_scenarios}).


We then benchmarked the ability of our model to identify such interactions and whether they confounded standard differential expression analyses. Our model exhibited high specificity and sensitivity by classifying only a small number of simulated genes (2\%) as exhibiting interaction effects in cases 1-2 where there are no covariate-pathway interactions but identifies 78\% and 63\% of genes as exhibiting significant covariate-pathway interactions in cases 3 and 4 respectively (tables \ref{tbl:fdr} and \ref{tbl:nclvm} and figure \ref{fig:simulations}). For comparison, a standard DE analysis using Limma-Voom identified 47\% and 59\% of genes as differentially expressed in cases 1 and 4 respectively. In case 2 only 2\% of genes are identified as DE as expected but, in case 3, 22\% of genes are identified as DE where Limma-Voom would not be expected to report any differentially expressed genes.

In our simulation study, Limma Voom ``only'' detects 47\% of the genes simulated as differentially expressed. Such power to detect differential expression is dependent on effect sizes and measurement noise, and so such a figure is in no way unreasonable given the parameters used. While a more comprehensive simulation study could examine detection rates across entire distributions over effect sizes and measurement noise, we simply sought to perform a simulation that demonstrated that PhenoPath identifies a subset of differential expression and that standard differential expression misses some interactions across a consistent effect size and noise regime.




\section{Applications of conditionally conjugate model}

\subsection{Single-cell RNA-seq} \label{sec:shalek}

\begin{figure}
\centering
\includegraphics[width=0.4\textwidth]{gfx/ch5/elbo_shalek.png}
\caption{Evidence lower bound (ELBO) as a function of CAVI iterations for the Shalek et al. dataset.}\label{fig:elbo_shalek}
\end{figure}

\begin{figure}
\centering
  \includegraphics[width=0.98\textwidth]{gfx/ch5/6_shalek_thesis.png}
  \caption{Stimulant-immune reactions single-cell RNA-sequencing data.
  \textbf{A} PhenoPath applied to the Shalek et al. dataset uncovers genes differentially regulated along pseudotime depending on the stimulant (LPS or PAM) applied.
  \textbf{B} PhenoPath infers pseudotimes ($z$) consistent with the physical capture times.
  \textbf{C} A comparison of $p$-values obtained through a nonparametric statistical test for differential expression between LPS and PAM stimulation shows no particular relation with the interaction parameters $\beta$ inferred with PhenoPath.
  \textbf{D} A GO enrichment analysis of the genes upregulated along pseudotime whose upregulation was increased by LPS stimulation showed enrichment for immune system processes.
  \textbf{E} Expression of the four genes with the largest interaction effect sizes along over pseudotime, stratified by stimulant applied. Strikingly, \emph{Tnf} is upregulated under PAM exposure yet downregulated under LPS stimulation.}  \label{fig:shalek}
\end{figure}

\begin{figure}
   \includegraphics[width=\textwidth]{gfx/ch5/7_s_compare_monocle_dpt.png}
   \caption{Performance of DPT and Monocle 2 on Shalek et al dataset.
\textbf{A} Sorted DPT pseudotimes by index identifies three outlier cells. \textbf{B} Comparison of DPT pseudotimes to PhenoPath pathway score $z$. \textbf{C} Comparison of Monocle 2 pseudotimes to PhenoPath pathway score $z$.}
	\label{fig:shalek_comparison}
\end{figure}

We next examined a time-series single-cell RNA-seq (scRNA-seq) data set of bone marrow derived dendritic cells responding to particular stimuli \cite{Shalek2014-cg}. Cells were exposed to LPS, a component of Gram-negative bacteria, and PAM, a synthetic mimic of bacterial lipopeptides, and scRNA-seq performed at 0, 1, 2, 4 and 6 hours after stimulation. Despite the time-series measurement, previous studies have suggested this dataset is more suited to a ``pseudotime'' analysis as the cells respond asynchronously and heterogeneity exists within the cellular populations at each time point\cite{Reid2016-yo}. To-date pseudotime inference algorithms would typically assume a common trajectory across all experimental conditions or a pseudotime analysis  performed separately for each stimulant. This might give a loss of statistical power and artifacts introduced by confounding effects. Using PhenoPath we can encode the stimulant to which the cells were exposed as a covariate and allow gene expression to evolve along pseudotime differently for either LPS or PAM exposure. This allows us to learn a single trajectory for all cells regardless of stimulant applied yet simultaneously infer which genes are differentially regulated in response. We applied this to the 820 cells exposed to LPS and PAM in the time points 1, 2, 4, and 6 hours after stimulation using the 7,533 genes whose variance in normalised log-expression exceeded a pre-set threshold (see appendix \ref{sec:prepclvm}). PhenoPath was run for approximately 250 CAVI iterations until convergence of the ELBO (figure \ref{fig:elbo_shalek}).

We inferred a covariate-perturbed trajectory using PhenoPath and uncovered a landscape of pseudotime-stimulant interactions (figure \ref{fig:shalek}A), unveiling genes whose regulation along pseudotime is modulated by the application of LPS or PAM. The trajectory inferred largely recapitulated the true time-series measurement (figure \ref{fig:shalek}B, $R^2 = 0.64$), despite no explicit temporal information being provided to the algorithm, though transcriptional heterogeneity at each time point is still evident. We also compared this to two commonly-used pseudotime algorithms and found that the pseudotimes inferred using PhenoPath had the best agreement with the capture times (figure \ref{fig:shalek_comparison}).


Using PhenoPath we found a large number of stimulant-modulated interactions masked by standard differential-expression analysis (figure \ref{fig:shalek}C). A GO analysis revealed genes whose upregulation along the common trajectory was increased by LPS exposure (as opposed to PAM) were highly enriched for immune response (figure \ref{fig:shalek}D), which recapitulates previous results\cite{Shalek2014-cg,Reid2016-yo} that suggest a ``core'' module of antiviral genes upregulated at later timepoints in LPS cells but in an entirely unsupervised, integrated manner. We finally examined the individual genes most perturbed by LPS or PAM along the trajectory (figure \ref{fig:shalek}E), which identifies as yet uncharacterised expression patterns associated with LPS and PAM. 
Most notably, the tumour necrosis factor \emph{Tnf} had around twice the interaction effect size of any other gene, and decreases under LPS stimulation but increases under PAM.
Further genes exhibit differential regulation according to stimulant, such as \emph{Mef2c} that has constant expression over pseudotime under LPS stimulation yet shows downregulation under PAM stimulation.
These results complement previously discovered gene differences such as that of \emph{Tnf}, but in a systematic, transcriptome-wide approach.

The Shalek et al. dataset of time-series dendritic cells was previously used in a pseudotime analysis where the capture times were explicitly used as priors on the latent space \cite{Reid2016-yo}. However, in PhenoPath we provide no explicit temporal information, so sought to perform a brief comparison to two popular pseudotime algorithms, Monocle 2 \cite{Qiu2017-eu} and DPT \cite{Haghverdi2016-eg}. For both methods we provided the same normalised log expression (see appendix \ref{sec:prepclvm}) and ran the algorithms with the default parameters. Performance of each algorithm was assessed by regressing the inferred pseudotimes on the capture times using the \texttt{R} function \texttt{lm} and computing the $R^2$. Oddly DPT has several "outlying" pseudotimes at the beginning of the trajectory (figure \ref{fig:shalek_comparison}) that we removed for both visualisation purposes and to compute a comparable $R^2$. The results gave an $R^2$ of $0.30$ and $0.03$ with the true capture time for DPT and Monocle 2 respectively, meaning PhenoPaths $R^2 = 0.64$ is significantly larger, perhaps because it accounts for differing stimulants applied. 


\subsection{Colorectal cancer bulk RNA-seq} \label{sec:coad}

\begin{figure}
\centering
\includegraphics[width=0.4\textwidth]{gfx/ch5/elbo_coad.png}
\caption{Evidence lower bound (ELBO) as a function of CAVI iterations for the COAD RNA-seq dataset.}\label{fig:elbo_coad}
\end{figure}

\begin{figure}
\includegraphics[width=0.98\textwidth]{gfx/ch5/8_coad_figure.png}
\caption{Immune-microsatellite instability interactions uncovered in colorectal adenocarcinoma.
\textbf{A} PhenoPath applied to colorectal adenocarcinoma (COAD) RNA-seq expression data uncovers a landscape of interactions between the inferred immune trajectory and microsatellite instability status (MSI).
\textbf{B} Expression of three T regulatory cell markers demonstrates that our pseudotime corresponds to activation of immune response pathways.
\textbf{C} A comparison to the FDR-corrected $q$-values reported by Limma Voom demonstrates genes found interacting with MSI status and the immune pathway are found to be both DE and non-DE in standard analyses.
\textbf{D} A GO enrichment analysis of upregulated genes implies the latent trajectory encodes immune pathway activation in each tumour.
\textbf{E} The tumour suppressor genes \emph{MLH1} and \emph{TGFBR2} were identified by our method as being significantly perturbed along the immune trajectory by MSI status. \emph{MLH1} shows no interaction with immune pathway activation in the MSI-low regime yet is highly correlated with immune pathway activation in the MSI-high regime.}
\label{fig:coad}
\end{figure}



We next applied our model to the RNA-seq gene expression data from the TCGA colorectal adenocarcinoma (COAD) cohort \cite{cancer2012comprehensive} using microsatellite instability status (MSI) as a phenotypic covariate. MSI is genetic hypermutability that is present in around 15\% of colorectal tumours and is associated with differential response to chemotherapeutics and marginally improved prognosis \cite{Boland2010-mz}. Due to a significant technical effect in the dataset we removed around half of samples (see appendix \ref{sec:prepclvm}), applying PhenoPath to 4,801 highly variable genes across 284 samples to identify a pseudotemporal trajectory through the tumours. PhenoPath was run for approximately 800 CAVI iterations until convergence of the ELBO (figure \ref{fig:elbo_coad}).

This analysis uncovered a landscape of 92 pathway-MSI interactions including known tumour suppressor genes (figure \ref{fig:coad}A).
Patients further advanced along the trajectory exhibited higher expression of T regulatory cell (Tregs) immune markers (figure \ref{fig:coad}B) likely due to increasing T regulatory cell infiltration of the tumour.
This led us to hypothesise that the inferred pathway corresponds to immune response activation in the tumours, further supported by a Gene Ontology (GO) enrichment analysis for genes upregulated along the trajectory   (figure \ref{fig:coad}C).
Tumour-infiltrating Tregs are potent immunosuppressive cells of the immune system that promote progression of cancer through their ability to limit antitumuor immunity and promote angiogenesis and often associated with a poor clinical outcome \cite{facciabene2012t}.
A standard differential expression analysis using Limma Voom \cite{Law2014-tu} (figure \ref{fig:coad}D) demonstrates that PhenoPath is required to uncover such interactions as a gene being differentially expressed does not imply a pathway-MSI interaction, while such interactions do not require differential expression.

The most striking interaction discovered for this dataset was the \mlh gene whose interaction effect size was far larger than any other gene.
\mlh is a DNA mismatch repair gene, germline mutations of which are causal for hereditary non-polyposis colorectal cancer\cite{Bonadona2011-ml,Gille2002-rx}.  By applying PhenoPath we correctly identified that in patients with low or absent levels of microsatellite instability there is no relationship between \mlh expression and immune pathway interaction, with \mlh expressed at an approximately constant level (figure \ref{fig:coad}E). However, when MSI occurs in a tumour, \mlh expression is highly correlated with immune response, showing almost no expression when the immune pathway is inactive and gradually being upregulated with immune pathway response\cite{michel2008high}.

\subsection{Breast cancer bulk RNA-seq} \label{sec:brca}

\begin{figure}
\centering
\includegraphics[width=0.4\textwidth]{gfx/ch5/elbo_brca.png}
\caption{Evidence lower bound (ELBO) as a function of CAVI iterations for the BRCA RNA-seq dataset.}\label{fig:elbo_brca}
\end{figure}

\begin{figure}
\includegraphics[width=0.98\textwidth]{gfx/ch5/9_brca_figure}
\caption{Vascular growth-ER status interactions uncovered by PhenoPath in breast cancer.
\textbf{A} PhenoPath applied to Breast Cancer (BRCA) RNA-seq expression data uncovers a landscape of interactions between the inferred angiogenesis trajectory and estrogen receptor (ER) status.
\textbf{B} A comparison to the FDR-corrected $q$-values reported by Limma Voom identifies a significant number of DE genes display an interaction with ER status and the angiogenic pathway.
\textbf{C} A GO enrichment analysis of upregulated genes implies the latent trajectory encodes angiogenesis pathway activation in each tumour.
\textbf{D} Four example genes \emph{ESR1}, \emph{FBP1}, and \emph{FOXC1} were identified by PhenoPath as significantly perturbed along the angiogenesis trajectory by ER status. The vertical dashed line signifies the calculated crossover point, demonstrating the expression profiles of these genes converge towards the end of the trajectory.
\textbf{E} A histogram of the crossover points of all genes whose trajectory-covariate interactions were significant. The vast majority of crossover points are at the end of the trajectory (around 0.5, where the ``middle'' pathway score is 0) implying a convergence of gene expression as the trajectory progresses.
} \label{fig:brca}
\end{figure}


We next performed a pseudotemporal analysis of the TCGA breast cancer cohort using estrogen receptor (ER) status as a phenotypic covariate. Approximately 60\% of breast cancers are estrogen receptor positive
\cite{Early_Breast_Cancer_Trialists_Collaborative_Group_EBCTCG_undated-ux}, which is typically associated with improved prognosis and a longer time to recurrence 
\cite{Parl1984-fo}. We applied PhenoPath to 1,135 samples post-QC and 4,579 highly variable genes. PhenoPath was run for approximately 2000 CAVI iterations until convergence of the ELBO (figure \ref{fig:elbo_coad}). Using stringent Bayesian significance testing criterion we found 1,932 genes (42\%) affected by an interaction between the pseudotemporal trajectory and ER receptor status (figure \ref{fig:brca}E).
 There was a correlation between the pathway interaction strength and the $p$-value reported through standard differential expression (Fig. \ref{fig:brca}B), though there remained some genes that exhibited pathway interaction and no differential expression.

\begin{figure}
   \includegraphics[width=\textwidth]{gfx/ch5/brca_genes.png}
   \caption{Pseudotemporally ordered gene expression trajectories for the TCGA Breast Cancer data for 12 breast cancer-associated genes.}
	\label{fig:brca_genes}
\end{figure}

A GO enrichment analysis indicated that the inferred pseudotemporal trajectory corresponded to vascular growth pathways or \emph{angiogenesis} (Fig. \ref{fig:brca}F) -- a well-known and uncontroversial hallmark of cancer development.\cite{ferrara2002vegf,welti2013recent} We confirmed this finding by specifically examining the expression of known angiogenesis inducing genes (Supplementary Fig. \ref{fig:vgf_genes}). We found increasing fibroblast growth factor-2 (\emph{FGF-2}) and vascular endothelial growth factors C and D (\emph{VEGF-C/D}) expression along the trajectory whose behaviours were independent of ER status.

\begin{figure}
   \includegraphics[width=\textwidth]{gfx/ch5/vgf_genes.png}
   \caption{Pseudotemporally ordered gene expression trajectories for the TCGA Breast Cancer data for six angiogenesis-associated genes.}
	\label{fig:vgf_genes}
\end{figure}

We finally sought to examine some genes PhenoPath identified as being most affected by the interaction between angiogenesis and estrogen receptor status.
Importantly, this set included the Estrogen Receptor 1 (\emph{ESR1})
gene as well as the forkhead transcription factors \emph{FOXA1} and \emph{FOXC1} which are known to be involved with ER$\alpha$ mediated action in breast cancer \cite{lam2013forkhead,yu2016foxc1} (Fig. \ref{fig:brca}D and Supplementary Fig. \ref{fig:brca_genes}).
Fig. \ref{fig:brca}D shows how the  ructose-1,6-biphosphatase (\emph{FBP1}) and \emph{FOXC1} genes evolve along the angiogenesis pathway dependent on ER status. In the ER- regime, \emph{FBP1} is upregulated along the trajectory while in the ER+ regime it is downregulated. Intriguingly, \emph{FBP1} has been identified as a marker to distinguish ER+ from ER- subtypes and its expression has been shown to be negatively correlated with \emph{SNAIL} as the Snail-G9a-Dnmt1 complex, is critical for E-cadherin promoter silencing, and required for the promoter methylation of FBP1 in basal-like breast cancer (Supplementary Fig. \ref{fig:fbp1-vs-snail}).\cite{dong2013loss} Similarly, \emph{FOXC1} shows no regulation in the ER- regime yet is strongly upregulated in the ER+ case.

\begin{figure}
  \centering
   \includegraphics[width=0.5\textwidth]{gfx/ch5/fbp1-vs-snail.png}
   \caption{\emph{FBP1} expression is inversely correlated with Snail in ER- breast cancers but shows no dependence in ER+ breast cancers.}
	\label{fig:fbp1-vs-snail}
\end{figure}

We noted that these genes represent a convergence - they have markedly different expression at the beginning of the trajectory based on ER status yet converge towards the end. We derived a mathematical formula to infer such convergence points and calculated these for all genes showing significant interactions (Supplementary Text). Remarkably, the vast majority converge towards the end of the trajectory (Fig. \ref{fig:brca}E), implying a common end-point in vascular development for both ER+ and ER- cancer subtypes (Supplementary Fig. \ref{fig:brca_convergence}).
This effect can be seen in the example expression plots in fiugre \ref{fig:brca}D, where the vertical dashed line represents the convergence point always at the end of the trajectory.
This suggests that while there exists low levels of angiogenesis pathway activation, ER status dominates gene expression while as angiogenesis pathway activation increases it comes to dominate expression patterns over ER status. This finding might have implications for the application of angiogenesis inhibitors in breast cancer treatment.

\begin{figure}
   \includegraphics[width=\textwidth]{gfx/ch5/brca-convergence.png}
   \caption{Expression of 20 genes with the largest interaction effects along the inferred pseudotemporal trajectory coloured by estrogen receptor status with linear fits as solid lines. The vertical dashed line indicates the crossover point.}
	\label{fig:brca_convergence}
\end{figure}


\section{Perturbations by censored survival times} \label{sec:survival}

\subsection{Modified statistical model}


We now suppose that $\mbx_n$ are not fully observed but represent partially observed survival times. In particular for each sample we observe the tuple $(o_n, \delta_n), \; n = 1, \ldots, N$ where $o_n$ is a survival time and $\delta_n$ is the censoring status, where $\delta_n = 1$ if $o_n$ is observed and $\delta_n = 0$ if $o_n$ is censored. We also introduce the true survival times $t_n, \; n = 1, \ldots, N$
where $t_n = o_n$ if $\delta_n = 1$ and $t_n > o_n$ if $\delta_n = 0$. In this $P = 1$ form let $\mbalpha \equiv \mbA_{:,1}$ and $\mbbeta \equiv \mbB_{:,1}$ be $G$-length vectors. The survival-adjusted latent variable model then takes the form

\begin{equation}
  \begin{aligned}
%\mbz_n & \sim \Norm(0, \mbI) \\
\mby_n & \sim \Norm\left( \mbalpha h(t_n) + (\mblambda + \mbbeta h(t_n)) z_n, \mbSigma \right).
  \end{aligned}
\end{equation}

where $h(t)$ is any desirable mapping function such as one that induces a variance-stablizing transformation.

If all the survival times $t_n$ were uncensored then such a model reduces to the form in equation \ref{eq:clvm} and inference can proceed as before. However, in many biomedical settings the majority of observations are censored, rendering such a problem intractable. We therefore turn our attention to creating a generative model of the censored true survival times that makes use of both the observed survival times and censoring times. % KC: This is a weird sentence

A classic choice for modelling survival times is the Weibull distribution parametrised by $\mbtheta_W = (k,p)$ with probability density function

\begin{equation}
  f_{\text{Weibull}}(t; k,p) = pkt^{k-1} \exp(-pt^k)
\end{equation}

and survival function $S_{\text{Weibull}}(t; k, p) = \int_t^\infty f(t'; k, p) dt' = \exp(-pt^k)$. We can then write the probability density of the true survival times as

\begin{equation}
  f(t_n; o_n, k, p) =
  \begin{cases}
    f_{\text{Weibull}}(t_n; k, p), \; \; \text{if $\delta_n = 1$} \\
    \frac{f_{\text{Weibull}}(t_n; k, p)}{S_{\text{Weibull}}(o_n; k, p)}, \; \; \; \text{if $\delta_n = 0$} \\
  \end{cases}
\end{equation}

where observed survival times are drawn from a Weibull distribution while censored survival times are drawn from a Weibull distribution truncated below at the censoring times (ie $p(t_n \leq o_n) = 0$ if $\delta_n = 0$).

\begin{figure}
  \centering
\includegraphics[width=0.45\textwidth]{gfx/ch5/model_diagram.png}
\caption{Survival-adjusted latent variable model, with data $\mby_n$, latent variables $z_n$, survival times $t_n$, and global parameters $\mbtheta_W$, $\mbbeta$, and $\mblambda$. The diamond represents the deterministic transform of the parameters to produce the observed data with sampling noise.} \label{fig:model}
\end{figure}

The overall generative model is represented in figure \ref{fig:model}. We place a further Sparse Bayesian Learning prior $\alpha_g \sim \Norm(0, \eta_g^{-1})$, $\alpha_g \stackrel{iid}{\sim} \Gam(a_\alpha, b_\alpha)$ and set $a_\alpha = b_\alpha = a_\beta = b_\beta = 10^{-2}$.



\subsection{Inference}


Our goal is Bayesian inference of the posterior $p(\mbz, \mbt^{cens}, \mbA, \mbB, \mblambda, \theta_W | \mbY, \mbo, \mbt^{obs}, \Psi)$ where $\Psi$ is the complete set of fixed hyperparameters. If we have $N_{\text{obs}} = \sum_{n = 1}^N \delta_n$ observed survival times and $N_{\text{cens}} = N - N_{\text{obs}}$ censored observations, we may reorder $\mbt$, $\mbo$,
$\mbdelta$, $\mbz$ and the rows of $\mbY$ so that the first $N_{\text{obs}}$ entries of $\mbdelta$ are 1 and the remaining $N_{\text{cens}}$ are 0. Then define $\mbt^{\text{cens}}$ and $\mbo^{\text{cens}}$ as the vector made of the first $N_{\text{cens}}$ entries of $\mbt$ and $\mbo$ respectively, and define $\mbt^{\text{obs}}$
as the vector of the final $N_{\text{obs}}$ entries of $\mbt$. Then the posterior factorises in the form

\begin{equation}
  \begin{aligned}
    p(\mbz, \mbt^{\text{cens}}, \mbalpha, \mbbeta, \mblambda, \theta_W, \mbsigma^2, \mbchi| \mbY, \mbo, \mbt^{\text{obs}}, \Psi)
    \propto & \; p(\mbY | \mbz, \mbt, \mbalpha, \mbbeta, \mblambda, \mbsigma^2) \\
     \times & p(\mbt^{\text{obs}} | \mbtheta_W) p(\mbt^{\text{cens}} | \mbo^{\text{cens}}, \mbtheta_W) \\
    \times & p(\mbalpha | \mbeta) p(\mbbeta | \mbchi) p(\mbeta) p(\mbchi) p(\mblambda) \\
    \times &  p(\mbz) p(\mbtheta_W) p(\mbsigma)
  \end{aligned}
\end{equation}

where we have omitted any dependency on hyperparameters.

\subsubsection{Black-box variational inference}

To infer posterior distributions over the entire set of latent variables $\mbTheta = \{\mbz, \mbt^{\text{cens}}, \mbalpha, \mbbeta, \mblambda, \theta_W, \mbsigma^2, \mbchi\}$ we posit a set of approximating distributions $q(\mbTheta | \mbPhi)$ with variational parameters $\mbPhi$. Inference then proceeds by finding estimates of $\mbPhi$ by minimising $\KL{q(\mbTheta | \mbPhi)}{p(\mbY, \mbo^{\text{cens}}, \mbt^{\text{obs}}, \mbTheta)}$,
which is equivalent to maximising the Evidence Lower Bound (ELBO) defined as $\text{ELBO}(\mbTheta) = \mbE_{q(\mbTheta)} \left[ p(\mbTheta, \mbY, \mbo^{\text{cens}}, \mbt^{\text{obs}}) - q(\mbTheta | \mbPhi))\right]$,
with respect to the variational parameters $\mbPhi$ for which we make a fully factorised mean-field approximation $q(\mbTheta | \mbPhi) = \prod_i q_i(\theta_i | \phi_i)$.
Inference of this model was implemented using the probabilistic programming language \texttt{Edward} \citep{Tran2016-ml} that allows for black-box variational inference of non-conditionally-conjugate models. The approximating distributions have reparameterizations (section \ref{sec:approx}), allowing us to sample from them via  $\epsilon \sim q(\epsilon), \; \theta_i = g_i(\epsilon, \phi_i)$ where $q(\epsilon)$ is a distribution independent of the variational parameters and $g_i$ is a deterministic transform. This allows us to use the reparametrization trick \citep{Kingma2013-wo} to compute noisy estimates of the gradient via

\begin{equation}
  \nabla_{\mbPhi} \text{ELBO}(\mbPhi) = \mbE_{q(\mbepsilon)}
  \left[
  \nabla_{\mbPhi} \left( \log p(\mbg(\mbepsilon, \mbPhi), \mbY, \mbo^{\text{cens}}, \mbt^{\text{obs}}) - \log q(\mbg(\mbepsilon, \mbPhi) | \mbPhi)\right)
  \right]
\end{equation}

where the expectation is computed via Monte-Carlo sampling.

\subsubsection{Choice of approximating distributions} \label{sec:approx}

For $\mbalpha, \mbbeta, \mbz$, and $\mblambda$ we posit variational approximations of the form $q(\theta_i) \sim \Norm(\mu_i, \sigma_i^2)$ which admits reparameterization via $\epsilon \sim \Norm(0, 1), \; \theta_i = \mu_i + \sigma_i \epsilon$. The variables $\mbchi$, $\mbsigma^2$, and $p$ are constrained to be positive, so we choose log-normal approximating distributions which is equivalent to the reparametrization $\epsilon \sim \Norm(0, 1), \; \theta_i = \exp(\mu_i + \sigma_i \epsilon)$.

The censored true survival times $\mbt^{\text{cens}}$ are bounded from below by the observed survival times, ie $t_n^{\text{cens}} > o_n$. However, in practice they are also upper bounded by the patient's maximum possible months remaining alive $r_n$. We can estimate $r_n$ for each patient by calculating the time from their date of diagnosis to the maximum possible human lifespan,  which we take to be 115 years. We subsequently construct a reparametrised variational approximation with variational parameters ($\mu_{t_n}, \sigma_{t_n}$):

\begin{equation} \label{eq:ttran}
  \begin{aligned}
  \epsilon & \sim \Norm(0, 1) \\
   t_n & = g_t(\epsilon | \mu_{t_n}, \sigma_{t_n}) = \frac{o_n + r_n e^{\mu_{t_n} + \sigma_{t_n} \epsilon}}{1 + e^{\mu_{t_n} + \sigma_{t_n}\epsilon}}
  \end{aligned}
\end{equation}

where $g_t(\epsilon) \in [o_n, r_n)$. Evaluation of $q(t_n | \mu_{t_n}, \sigma_{t_n}, o_n, r_n)$ is then made via $q(t_n | \mu_{t_n}, \sigma_{t_n}, o_n, r_n) = \Norm(\epsilon | 0, 1) \left| \frac{\partial g^{-1}_t(\epsilon | \mu_{t_n}, \sigma_{t_n})}{\partial \epsilon} \right|$.

The variable $k$ parametrizing the Weibull distribution is constrained to be greater than zero. It further has an intuitive interpretation: for $k < 1$ the failure rate decreases over time, for $k = 1$ the failure rate is constant, while for $k > 1$ the survival rate increases over time. For most biomedical applications (see section \ref{sec:tcga}) it is known the survival rate increases over time, so we may constrain $k > 1$. However, $k$ appears in the log-likelihood via $\sum_n t_n^k$, where $t_n$ is both the observed and censored true survival times. Thus in settings where $t_n$ may exceed orders of $10^2$ and $k$ sampled from a log-normal distribution, $t_n^k$ leads to highly unstable estimates of the log-likelihood and can easily overflow the machine precision. Thus we constrain $k$ to be on the interval $[a, b)$ via the same reparametrization as in equation \ref{eq:ttran} and  set $a = 1$ and $b = 3$.


\subsection{Application to breast cancer bulk RNA-seq}


We applied our model to RNA sequencing data and survival times from breast cancer samples in the Cancer Genome Atlas \citep{Weinstein2013-ww,tatlow2016cloud}. This resource includes 1137 patients of which 180 (16\%) have recorded survival times and the remaining 957 have censored survival times. Gene expression estimates from RNA sequencing counts have been shown to follow a log-normal distribution \citep{Law2014-tu,Pimentel2016-xz}, so our input data consisted of transforming the raw transcripts-per-million $x$ via $\tilde{x} = \log(x + 1)$. The survival times (both observed and censored) followed a highly right-skewed distribution so we chose $h(t) = \log(t + 1)$ as a variance-stabilising transformation.

\subsubsection{Imputation of survival times}

\begin{figure}
  \centering
\includegraphics[width=\textwidth]{gfx/ch5/censoring_figure.png}
\caption{Imputation of survival times. Weibull plots of (\textbf{a}) observed  and (\textbf{b}) imputed  survival times $t_n$, where $\hat{F}$ is the empirical cumulative distribution function for the MAP estimates of $k$ and $\lambda = p^{-k}$. If the survival times were truly drawn from the fitted Weibull distribution the points would fall along the diagonal $y=x$ (dashed line).
\textbf{(c)} Histograms of the observed and imputed survival times $t_n$ along with the unnormalised Weibull density (dashed line) at the MAP estimates of $\mbtheta_W$ shown by the dashed line.
\textbf{(d)} Deviations of the imputed survival times $t^{\text{cens}}_n$ compared to their censoring times $o^{\text{cens}}_n$ as a function of censoring times. Error bars show the posterior $2 \sigma$ interval.
} \label{fig:censoring_figure}
\end{figure}

%A feature of such a generative model is we can infer maximum a posteriori (MAP) estimates of the true survival times.
We sought to assess the suitability of the Weibull distribution for modelling survival times compared to nonparametric alternatives such as Cox proportional hazards model using a \emph{Weibull plot}. Here, if the survival times are truly drawn from the Weibull distribution then the graph of $\log(-\log(1 - \hat{F}(t)))$ against $k \log(t) - k \log(\lambda)$ will fall along the diagonal $y=x$, where $\hat{F}$ is the empirical distribution function and $\lambda = p^{-k}$.

Weibull plots for both $\mbt^{\text{obs}}$ and $\mbt^{\text{cens}}$ are shown in figures \ref{fig:censoring_figure} (\textbf{a}) and (\textbf{b}) respectively for the MAP estimates of $k$ and $p$. The data fit the Weibull distribution well falling close to the dashed diagonal $y=x$ line, except in the case of the imputed survival times for low $t_n$ where we see deviations.
An further alternative representation is shown by the histogram in figure \ref{fig:censoring_figure}(\textbf{c}).%, where the distribution of the observed and imputed survival times visually fit the unnormalised MAP Weibull density well.
We also examined the MAP estimates of the imputed survival times $t_n^{\text{cens}}$ compared to the censoring times $o_n^{\text{cens}}$ as seen in figure \ref{fig:censoring_figure}(\text{d}). The imputed $t_n^{\text{cens}}$ typically lie close to the observed $o_n^{\text{cens}}$,
which is expected given the log-normal approximating distribution $q(t_n)$ constrained below at $o_n$.

\subsubsection{Patient trajectory interactions}

\begin{figure}
  \centering
\includegraphics[width=\textwidth]{gfx/ch5/brca_plot.png}
\caption{Results on breast cancer gene expression data.
(\textbf{a}) Comparison of the inferred latent variables $z_n$ to the first principal component of the data. Different trajectories are visible for long survival times (which largely mimics PC1) to short survival times, which departs from PC1 on a separate trajectory.
(\textbf{b}) A plot of MAP $\chi_g^{-1}$ versus $\beta_g$ identifies significant interactions between the inferred latent variables and survival times.
(\textbf{c}) A hierarchical clustering of expression of genes designated significant from (\textbf{b}) reveals two main classes of expression programme over along $z_n$, segregating into those involved in signal transduction and cell cycle dependent genes.
(\textbf{d}) LOESS fits of mean standardized expression of each gene type from (\textbf{c}) stratified into patients in the lowest quantile of survival times compared to the highest quantile of survival times.
} \label{fig:brca}
\end{figure}

We first compared our inferred latent variables $z_n$ to the first principal component of the data. Setting $\alpha_g = \beta_g = 0\; \forall g$ (which is encouraged by the ARD prior) will recover a rank-one factor analysis in the model, which in the limit of isotropic measurement variance reduces to (probabilistic) principal component analysis (PCA). Therefore, such a comparison serves to qualitatively identify the effect to which the covariates perturb the trajectory.

The comparison can be seen in figure \ref{fig:brca}(\textbf{a}) coloured by the logarithm of the true survival time. We can visually identify that for longest survival times the latent trajectory largely follows that of principal component analysis, while for short survival times it deviates substatially. In case such a result was driven by a few outlying samples we removed the patients whose event times (survival or censoring) were less than 1 (38/1137) and repeated the analysis, finding good correlation between the values of $\mbbeta$ ($\rho_{\text{pearson}} = 0.96$).

We subsequently performed a gene ontology (GO) enrichment analysis to identify the biological characteristics of the inferred trajectory. Many genes in the human genome are annotated with \emph{ontologies} that describe biological processes the genes are involved in. We can therefore perform statistical tests \citep{young2010gene} that identify which ontologies are over-represented in a given set compared to a background population alone. Performing such a test on genes whose Pearson correlation of expression with the inferred trajectory exceeded 0.5 identified processes related to vascular growth, also known as angiogenesis. Therefore, the trajectory $z_n$ loosely corresponds to a continuous score of angiogenesis pathway activation in each of the breast cancer tumours.


Figure \ref{fig:brca}(\textbf{b}) shows the posterior estimates of $\chi_g^{-1}$ against the posterior estimates of $\beta_g$ coloured by whether the interaction is identified as significant. % or not using the criterion from \ref{sec:signif}.
A total of 2,371 genes (42\% of those included) exhibited a significant interaction between the inferred angiogenesis trajectory and the survival times of the patients. Many of the genes with the largest $\beta$ effect sizes are previously implicated in cancer progression: \emph{SDPR} acts as a metastasis suppressor \citep{ozturk2016sdpr}, \emph{PRMT1} promotes mitosis in
cancer cells \citep{deng2015prmt1}, \emph{PRMT1} modulates the epithelial-mesenchymal transition and cellular senescence in breast cancer cells \citep{gao2016dual}, while \emph{TOP2A} is a predictive marker of chemotherapy efficacy \citep{wang2012top2a}.

We next performed hierarchical clustering on the expression profiles of the 2,371 genes that showed significant interactions between angiogensis and survival time, as shown in figure \ref{fig:brca}(\textbf{c}). This identified two main classes of genes whose expression programmes followed correlated expression patterns. %KC: I'm going to purgatory for this sentence
A further GO analysis individually on each gene set revealed their biological relevance.
The first contains genes involved in signal transduction - the cell to cell communication through the transmission of signalling molecules - dysregulation of which is a major cause of cancer progression \citep{Sever2015-ru}.
The second set contains genes associated with cell cycle - the sequence of events leading to cell division that leads to cancerous growth when uncontrolled. We subsequently formed smoothed expression profiles of each gene set along the vascular growth trajectory, stratified by those patients in the lowest quantile of survival times and those in the highest (figure \ref{fig:brca}(\textbf{d})). For patients with the shortest survival times the signal transduction pathway exhibits near constant expression for low $z_n$ before gradual upregulation, while for the longest survival times the gene set is expressed at later $z_n$ but experiences quicker upregulation. Similarly, for the cell cycle genes patients with the shortest survival times experience transient expression across $z_n$ with slow downregulation, while patients with the longest survival times experience quick downregulation along $z_n$.

\section{Covariate-adjusted Gaussian Process Latent Variable Models}


\subsection{Marginalising over the mapping}

One limitation of the model is its linear nature, making inferred latent variables similar to those from factor analysis. We therefore propose a nonlinear, nonparametric extension similar to Gaussian Process Latent Variable Models \citep{Lawrence2005-cu} that were previously discussed in section \ref{sec:gplvm}.

%The trick is to consider the $\mbX\mbX^T$ term in the covariance matrix of the marginal distribution of $\mbY$ and replace it with any (semi-)positive definite matrix representing ``similarity'' between the elements of $\mby$, such as double-exponential kernels.
%We previously suggested \emph{Covariate-adjusted Gaussian Process Latent Variable Models} (C-GPLVM, \cite{Campbell2016-nu}), which for a fixed covariate $\mbx \in \mathbb{R}^N$ has kernels including  $K(\mbx \odot \mbz, \mbx \odot \mbz')$ where $\odot$ denotes element-wise multiplication so $(\mbx \odot \mbz)_i = x_i z_i$.

We wish to marginalise over the mapping $\{\mbalpha, \mbbeta, \mblambda\}$ with priors
$\alpha_g \sim \Norm(0, \sigma^2_{\alpha,g})$,
$\beta_g \sim \Norm(0, \sigma^2_{\beta,g})$,
$\lambda_g \sim \Norm(0, \sigma^2_{\lambda,g})$.
This leads to a multivariate normal likelihood for each $\mby_g$  (where $\mby_g$ is the $g^{\text{th}}$
column vector of $\mbY$) given by

\begin{equation}
  \mby_g | \cdot \sim
  \Norm\left(\mbzero, \sigma_{\alpha,g}^2 \mbx \mbx^T + \sigma_{\lambda,g}^2 \mbz \mbz^T +
  \sigma_{\beta,g}^2 (\mbx \odot \mbz)(\mbx \odot \mbz)^T + \sigma_g^2 \mbI_N
  \right)
\end{equation}

where $\odot$ denotes element-wise multiplication ($[\mbx \odot \mby]_i = x_i y_i$), $\mbI_N$ is the $N \times N$ identity matrix and $\sigma_g$ is the residual (measurement) variance not explained by the model.

The trick to derive a Gaussian Process Latent Variable-like model from here is two-fold. Firstly, Lawrence (2005) \cite{Lawrence2005-cu} noted that entries in the low-rank covariance structure $\mbx \mbx^T$ loosely represent ``similarity'' between samples and can thus be replaced by any kernel $K(x,x')$. Secondly, the sum of kernels is also a valid kernel so if $K_1(x,x')$ and $K_2(x,x')$ are two kernels then  $\alpha K_1(x,x') + \beta K_1(x,x')$ also represents a valid kernel for some scalars $\alpha, \beta > 0$. We therefore introduce the concept of \emph{Covariate-adjusted Gaussian Process Latent Variable Models} (CGPLVMs) that have kernels of the form

\begin{equation} \label{eq:clvm_kernel}
K\left( \{\mbx, \mbz\}, \{\mbx', \mbz'\} \right) \propto K(\mbx, \mbx') + K(\mbz, \mbz') +
K(\mbx \odot \mbz,\mbx' \odot \mbz')
\end{equation}

\begin{figure}
  \centering
\includegraphics[width=0.85\textwidth]{gfx/ch5/cgplvm_prior}
\caption{Draws from a CGPLVM prior with $\lambda = 0.5$, $\gamma = \nu = \eta = \delta = 0.2$ and $\xi \in \{0, 0.1, 0.5, 1\}$. For small $\xi$ an identical trajectory is taken regardless of $x$ but as $\xi$ increases differing trajectories become apparent.} \label{fig:cgplvm_prior}
\end{figure}


for some choice of kernel function $K$ such as the squared exponential kernel $k_{\text{SQE}}(x, x') = \sigma_f^2 \exp\left(-\frac{1}{2l^2}(x - x')^2\right)$. In this case the kernel for the $g^{\text{th}}$ output dimension (typically genes in a biological context) is given by

\begin{equation}
  \begin{aligned}
  K_g(x, z; x', z') & =
  \delta_g \exp(-\eta_g (x - x')^2) +
  \nu_g \exp(-\gamma_g(z - z')^2) \\
  & + \xi_g \exp(-\lambda_g(xz - x'z')^2)
\end{aligned}
\end{equation}

where $\{\mbdelta, \mbeta, \mbnu, \mbgamma, \mbxi, \mblambda\}$ are the complete set of kernel parameters. Example draws from the GP priors of such kernels can be seen in figure \ref{fig:cgplvm_prior}.


Note that the interactions between the latent variables and the covariates appear linearly (through the element-wise multiplication) because this was the formulation in the original model. These interactions may therefore be made nonlinear by replacing the third term in the covariance of equation \ref{eq:clvm_kernel} with $K(\mbf(\mbx, \mbz), \mbf(\mbx', \mbz'))$ where $\mbf$ is any function that obeys $[\mbf(\mbx, \mbz)]_i = f(x_i, z_i)$ (i.e. $\mbf$ acts element-wise along the vectors $\mbz$ and $\mbx$.)



\subsection{Black-box inference}


\begin{figure}
  \centering
\includegraphics[width=1.1\textwidth]{gfx/ch5/thesis_features_all}
\caption{Synthetic data used to test CGPLVM for $N=50$ samples and $G=10$ features, with kernel parameters $\eta = 0.2$, $\gamma \nu = \delta = \xi = 1$, and $\sigma^2 = 0.01$. The first 5 features had $\lambda = 0.2$ and the final 5 had $\lambda = 0$.} \label{fig:cgplvm_data}
\end{figure}

As a small proof-of-concept we created a synthetic dataset (figure \ref{fig:cgplvm_data}) for $N=50$ samples and $G=10$ features, with $z$ drawn from $\text{Unif(-1, 1)}$ and the covariates sampled randomly from $\{-1, -0.5, 0, 0.5, 1\}$. The kernel parameters were fixed to $\eta = 0.2$, $\gamma \nu = \delta = \xi = 1$, and $\sigma^2 = 0.01$. The first 5 features had $\lambda = 0.2$ and the final 5 had $\lambda = 0$ so that half the features exhibited covariate-latent variable interactions. The model was implemented in the probabilistic programming language \texttt{Stan} with hierarchical priors $\lambda_g \sim \chi^2(1)$, $z_n \sim \Norm(0,1)$ and $1 / \sigma^2 \sim \text{Gamma}(0.1, 0.1)$.
\texttt{Stan} was run for 4000 iterations (2000 burn-in) with the latent variables initialised to the first principal component of the data.



\begin{figure}
  \centering
\includegraphics[width=0.9\textwidth]{gfx/ch5/cgplvm_results}
\caption{Black-box inference for CGPLVM on synthetic data.
\textbf{A} Comparison of posterior mean inferred $z$ from CGPLVM vs. true $z$.% has $\rho_{Pearson} = 0.998$.
\textbf{B} Same comparison with first principal component of the data. % has $\rho_{Pearson} = 0.971$.
\textbf{C} Traceplot of the posterior log-likelihood suggests good convergence of the model.
\textbf{D} Posterior boxplot of $\mblambda$ identifies interactions for the odd-numbered features.
} \label{fig:cgplvm_results}
\end{figure}

The results can be seen in figure \ref{fig:cgplvm_results}. Figure \ref{fig:cgplvm_results}A compares the true latent variable values $z$ to those inferred by the model, demonstrating high correlation (with the exception of two points). Figure \ref{fig:cgplvm_results}B compares the first principal component of the data to the true values, showing obviousl correlation but also confounding due to $x$. An initial analysis suggests the HMC algorithm has converged (figure \ref{fig:cgplvm_results}C) due to good mixing of the log-posterior. Also of interest was the ability of the model to detect interactions between $x$ and $z$ in the Gaussian Process model. To do this we an examine boxplots of the posterior of $\mblambda$. Figure \ref{fig:cgplvm_results}D demonstrates that the first 5 features (that were designed with interactions in the synthetic data) have higher posterior mean values than the second five, demonstrating such models are able to detect interactions.


\section{Discussion}

\begin{itemized}
\item SVI instead of CAVI
\item Hyperpars for cgplvm
\item inducing points
\item FA step in linear clvm
\end{itemized}